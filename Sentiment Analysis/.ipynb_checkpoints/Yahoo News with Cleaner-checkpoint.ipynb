{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import csv\n",
    "from time import sleep\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # # NEWS API STREAMER # # # #\n",
    "class ArticleStreamer():\n",
    "    \"\"\"\n",
    "    Class for streaming and processing articles daily\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def get_article(self, card):\n",
    "        \"\"\"Extract article information from the raw html\"\"\"\n",
    "        headline = card.find('h4', 's-title').text\n",
    "        source = card.find(\"span\", 's-source').text\n",
    "        posted = card.find('span', 's-time').text.replace('·', '').strip()\n",
    "        description = card.find('p', 's-desc').text.strip()\n",
    "        raw_link = card.find('a').get('href')\n",
    "        unquoted_link = requests.utils.unquote(raw_link)\n",
    "        pattern = re.compile(r'RU=(.+)\\/RK')\n",
    "        clean_link = re.search(pattern, unquoted_link).group(1)\n",
    "\n",
    "        article = (headline, source, posted, description, clean_link)\n",
    "        return article\n",
    "\n",
    "    def get_the_news(self, query):\n",
    "        \"\"\"Run the main program\"\"\"\n",
    "        article_headers = ['title', 'outlet', 'uploaded', 'description', 'url']\n",
    "        \n",
    "        template = 'https://news.search.yahoo.com/search?p={}'\n",
    "        url = template.format(query)\n",
    "        articles = []\n",
    "        links = set()\n",
    "\n",
    "        while True:\n",
    "            response = requests.get(url, headers=headers)\n",
    "            soup = BeautifulSoup(response.text, 'html.parser')\n",
    "            cards = soup.find_all('div', 'NewsArticle')\n",
    "\n",
    "            # extract articles from page\n",
    "            for card in cards:\n",
    "                article = self.get_article(card)\n",
    "                link = article[-1]\n",
    "                if not link in links:\n",
    "                    links.add(link)\n",
    "                    articles.append(article)\n",
    "\n",
    "                    # find the next page\n",
    "            try:\n",
    "                url = soup.find('a', 'next').get('href')\n",
    "                sleep(1)\n",
    "            except AttributeError:\n",
    "                break\n",
    "        \n",
    "        all_articles = pd.DataFrame(articles, columns = article_headers)\n",
    "\n",
    "        return all_articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ArticleCleaner():\n",
    "    \"\"\"\n",
    "    Functionality for importing and cleaning news articles\n",
    "    \"\"\"\n",
    "\n",
    "    def import_json(self, fetched_json_file):\n",
    "        # Import json and normalize data\n",
    "        df = pd.read_json(fetched_json_file)\n",
    "        norm_articles = pd.json_normalize(df['articles'])\n",
    "\n",
    "        return norm_articles\n",
    "\n",
    "    def clean_article(self, article):\n",
    "        return ' '.join(re.sub(\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\", \" \", article).split())\n",
    "\n",
    "    def create_article(self, articles):\n",
    "        article = articles[['author', 'title', 'description', 'url', 'source.name', 'publishedAt']]\n",
    "        outlet = articles[['source.id', 'source.name']]\n",
    "\n",
    "        return article, outlet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index(['author', 'title', 'description', 'url', 'source.name', 'publishedAt'], dtype='object')] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-3950b948e88b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[0mall_articles\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marticle_streamer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_the_news\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m     \u001b[0marticles\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutlets\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marticle_cleaner\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_article\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_articles\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[0mclean_title\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0marticle_cleaner\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclean_article\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marticle\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0marticle\u001b[0m \u001b[1;32min\u001b[0m \u001b[0marticles\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'title'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-16-d1d6f188efcb>\u001b[0m in \u001b[0;36mcreate_article\u001b[1;34m(self, articles)\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mcreate_article\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marticles\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m         \u001b[0marticle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marticles\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'author'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'title'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'description'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'url'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'source.name'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'publishedAt'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m         \u001b[0moutlet\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marticles\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'source.id'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'source.name'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2804\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2805\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2806\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2807\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2808\u001b[0m         \u001b[1;31m# take() does not accept boolean indexers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[1;34m(self, key, axis, raise_missing)\u001b[0m\n\u001b[0;32m   1550\u001b[0m             \u001b[0mkeyarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_indexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reindex_non_unique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1551\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1552\u001b[1;33m         self._validate_read_indexer(\n\u001b[0m\u001b[0;32m   1553\u001b[0m             \u001b[0mkeyarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_axis_number\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mraise_missing\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1554\u001b[0m         )\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_validate_read_indexer\u001b[1;34m(self, key, indexer, axis, raise_missing)\u001b[0m\n\u001b[0;32m   1638\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mmissing\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1639\u001b[0m                 \u001b[0maxis_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_axis_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1640\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"None of [{key}] are in the [{axis_name}]\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1641\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1642\u001b[0m             \u001b[1;31m# We (temporarily) allow for some missing keys with .loc, except in\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"None of [Index(['author', 'title', 'description', 'url', 'source.name', 'publishedAt'], dtype='object')] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    fetched_json_file = './news_articles.json'\n",
    "    query = 'cryptocurrency'\n",
    "    headers = {\n",
    "        'accept': '*/*',\n",
    "        'accept-encoding': 'gzip, deflate, br',\n",
    "        'accept-language': 'en-US,en;q=0.9',\n",
    "        'referer': 'https://www.google.com',\n",
    "        'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/85.0.4183.83 Safari/537.36 Edg/85.0.564.44'\n",
    "    }\n",
    "\n",
    "    article_cleaner = ArticleCleaner()\n",
    "    article_streamer = ArticleStreamer()\n",
    "\n",
    "    all_articles = article_streamer.get_the_news(query)\n",
    "\n",
    "    articles, outlets = article_cleaner.create_article(all_articles)\n",
    "\n",
    "    clean_title = np.array([article_cleaner.clean_article(article) for article in articles['title']])\n",
    "    clean_desc = np.array([article_cleaner.clean_article(article) for article in articles['description']])\n",
    "\n",
    "    articles['clean_title'] = clean_title\n",
    "    articles['clean_description'] = clean_desc\n",
    "\n",
    "    articles.to_csv(r'.\\cleaned_articles_crypto.csv', index=False)\n",
    "    outlets.to_csv(r'.\\outlets.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accept</th>\n",
       "      <th>accept-encoding</th>\n",
       "      <th>accept-language</th>\n",
       "      <th>referer</th>\n",
       "      <th>user-agent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ethereum price hits record high amid ‘cryptocu...</td>\n",
       "      <td>The Independent via Yahoo News</td>\n",
       "      <td>54 minutes ago</td>\n",
       "      <td>The cryptocurrency reached $1,430 (£1,044) on ...</td>\n",
       "      <td>https://www.yahoo.com/finance/news/ethereum-pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Trustee of Collapsed Exchange Moves to Resolve...</td>\n",
       "      <td>CoinDesk via Yahoo Finance</td>\n",
       "      <td>3 hours ago</td>\n",
       "      <td>Ernst and Young (EY), the bankruptcy trustee f...</td>\n",
       "      <td>https://finance.yahoo.com/news/trustee-collaps...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bitcoin Steady as Analysts Say Getting Back to...</td>\n",
       "      <td>Bloomberg via Yahoo Finance</td>\n",
       "      <td>2 days ago</td>\n",
       "      <td>Bitcoin hovered near $36,000 on Monday, below ...</td>\n",
       "      <td>https://finance.yahoo.com/news/bitcoin-retreat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bitcoin Crash Is Excellent Opportunity to Buy ...</td>\n",
       "      <td>InvestorPlace via Yahoo Finance</td>\n",
       "      <td>5 days ago</td>\n",
       "      <td>The cryptocurrency is still up roughly 89% on ...</td>\n",
       "      <td>https://finance.yahoo.com/news/bitcoin-crash-e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>First Mover: Ethereum Steals Limelight With Ne...</td>\n",
       "      <td>CoinDesk via Yahoo Finance</td>\n",
       "      <td>22 hours ago</td>\n",
       "      <td>“This period of consolidation is building a so...</td>\n",
       "      <td>https://finance.yahoo.com/news/first-mover-eth...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>727</th>\n",
       "      <td>Dow Jones Today, Nasdaq Futures Lag In First W...</td>\n",
       "      <td>Investor's Business Daily</td>\n",
       "      <td>5 days ago</td>\n",
       "      <td>Analyst actions and earnings news stirred a la...</td>\n",
       "      <td>https://www.investors.com/market-trend/stock-m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>728</th>\n",
       "      <td>Man offers Newport Council £50m to help him fi...</td>\n",
       "      <td>The Telegraph via Yahoo News</td>\n",
       "      <td>5 days ago</td>\n",
       "      <td>A Welshman was on Friday offering local offici...</td>\n",
       "      <td>https://www.yahoo.com/finance/news/man-offers-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>729</th>\n",
       "      <td>What's Next for Bitcoin? Examining Its Adoptio...</td>\n",
       "      <td>ETF Trends</td>\n",
       "      <td>5 days ago</td>\n",
       "      <td>Among the long list of issues facing Bitcoin a...</td>\n",
       "      <td>https://www.etftrends.com/crypto-channel/whats...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>730</th>\n",
       "      <td>Top 3 Price Prediction Bitcoin, Ethereum, Ripp...</td>\n",
       "      <td>The Forex Market</td>\n",
       "      <td>5 days ago</td>\n",
       "      <td>The ECB is pushing for a digital euro in five ...</td>\n",
       "      <td>https://www.fxstreet.com/cryptocurrencies/news...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>731</th>\n",
       "      <td>New to The Street brings its Line-Up of \"Game ...</td>\n",
       "      <td>Morningstar</td>\n",
       "      <td>5 days ago</td>\n",
       "      <td>NEW YORK, NY / ACCESSWIRE / January 15, 2021 /...</td>\n",
       "      <td>https://www.morningstar.com/news/accesswire/62...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>732 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                accept  \\\n",
       "0    Ethereum price hits record high amid ‘cryptocu...   \n",
       "1    Trustee of Collapsed Exchange Moves to Resolve...   \n",
       "2    Bitcoin Steady as Analysts Say Getting Back to...   \n",
       "3    Bitcoin Crash Is Excellent Opportunity to Buy ...   \n",
       "4    First Mover: Ethereum Steals Limelight With Ne...   \n",
       "..                                                 ...   \n",
       "727  Dow Jones Today, Nasdaq Futures Lag In First W...   \n",
       "728  Man offers Newport Council £50m to help him fi...   \n",
       "729  What's Next for Bitcoin? Examining Its Adoptio...   \n",
       "730  Top 3 Price Prediction Bitcoin, Ethereum, Ripp...   \n",
       "731  New to The Street brings its Line-Up of \"Game ...   \n",
       "\n",
       "                     accept-encoding accept-language  \\\n",
       "0     The Independent via Yahoo News  54 minutes ago   \n",
       "1         CoinDesk via Yahoo Finance     3 hours ago   \n",
       "2        Bloomberg via Yahoo Finance      2 days ago   \n",
       "3    InvestorPlace via Yahoo Finance      5 days ago   \n",
       "4         CoinDesk via Yahoo Finance    22 hours ago   \n",
       "..                               ...             ...   \n",
       "727        Investor's Business Daily      5 days ago   \n",
       "728     The Telegraph via Yahoo News      5 days ago   \n",
       "729                       ETF Trends      5 days ago   \n",
       "730                 The Forex Market      5 days ago   \n",
       "731                      Morningstar      5 days ago   \n",
       "\n",
       "                                               referer  \\\n",
       "0    The cryptocurrency reached $1,430 (£1,044) on ...   \n",
       "1    Ernst and Young (EY), the bankruptcy trustee f...   \n",
       "2    Bitcoin hovered near $36,000 on Monday, below ...   \n",
       "3    The cryptocurrency is still up roughly 89% on ...   \n",
       "4    “This period of consolidation is building a so...   \n",
       "..                                                 ...   \n",
       "727  Analyst actions and earnings news stirred a la...   \n",
       "728  A Welshman was on Friday offering local offici...   \n",
       "729  Among the long list of issues facing Bitcoin a...   \n",
       "730  The ECB is pushing for a digital euro in five ...   \n",
       "731  NEW YORK, NY / ACCESSWIRE / January 15, 2021 /...   \n",
       "\n",
       "                                            user-agent  \n",
       "0    https://www.yahoo.com/finance/news/ethereum-pr...  \n",
       "1    https://finance.yahoo.com/news/trustee-collaps...  \n",
       "2    https://finance.yahoo.com/news/bitcoin-retreat...  \n",
       "3    https://finance.yahoo.com/news/bitcoin-crash-e...  \n",
       "4    https://finance.yahoo.com/news/first-mover-eth...  \n",
       "..                                                 ...  \n",
       "727  https://www.investors.com/market-trend/stock-m...  \n",
       "728  https://www.yahoo.com/finance/news/man-offers-...  \n",
       "729  https://www.etftrends.com/crypto-channel/whats...  \n",
       "730  https://www.fxstreet.com/cryptocurrencies/news...  \n",
       "731  https://www.morningstar.com/news/accesswire/62...  \n",
       "\n",
       "[732 rows x 5 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
