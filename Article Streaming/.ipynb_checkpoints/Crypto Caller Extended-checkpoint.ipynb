{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import csv\n",
    "from time import sleep\n",
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import bs4\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime, timedelta, date\n",
    "\n",
    "import pandas_datareader as pdr\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from newsapi import NewsApiClient\n",
    "from yahoofinancials import YahooFinancials\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # # NEWS API AUTHENTICATER # # # #\n",
    "class NewsAuthenticator():\n",
    "\n",
    "    def authenticate_news_api(self):\n",
    "        auth = NewsApiClient(api_key='cc3f4e3191f149658f3922e9c47ec1ad')\n",
    "        return auth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # # NEWS API STREAMER # # # #\n",
    "class NewsAPIArticleStreamer():\n",
    "    \"\"\"\n",
    "    Class for streaming and processing articles daily\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.news_authenticator = NewsAuthenticator()    \n",
    "\n",
    "    def stream_articles(self, query, from_param, to):\n",
    "        # This handles Twitter authetification and the connection to Twitter Streaming API\n",
    "        newsapi = self.news_authenticator.authenticate_news_api()\n",
    "        all_articles = newsapi.get_everything(q=query,\n",
    "                                          from_param= from_param,\n",
    "                                          to= to,\n",
    "                                          language='en')\n",
    "        \n",
    "        return all_articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NewsAPIArticleCleaner():\n",
    "    \"\"\"\n",
    "    Functionality for importing and cleaning news articles\n",
    "    \"\"\"\n",
    "    def import_json(self, fetched_json_file):\n",
    "        # Import json and normalize data\n",
    "        df = pd.read_json(fetched_json_file)\n",
    "        norm_articles = pd.json_normalize(df['articles'])\n",
    "        \n",
    "        return norm_articles\n",
    "\n",
    "    def clean_article(self, article):\n",
    "        return ' '.join(re.sub(\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\", \" \", article).split())\n",
    "    \n",
    "    def create_article(self, articles):\n",
    "        article = articles[['author', 'title', 'description', 'url', 'source.name', 'publishedAt']]\n",
    "        article['publishedAt'] = pd.to_datetime(article['publishedAt'], infer_datetime_format=True)\n",
    "        article.sort_values(by='publishedAt',inplace=True)\n",
    "        article = article.reset_index()\n",
    "        article = article.drop(['index'], axis=1)\n",
    "        \n",
    "        outlet = articles[['source.id', 'source.name']]\n",
    "        \n",
    "        return article, outlet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # # YAHOO FINANCE STREAMER # # # #\n",
    "class YahooArticleStreamer:\n",
    "    \"\"\"\n",
    "    Class for streaming and processing articles daily\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def get_article(self, card):\n",
    "        \"\"\"Extract article information from the raw html\"\"\"\n",
    "        headline = card.find('h4', 's-title').text\n",
    "        source = card.find(\"span\", 's-source').text\n",
    "        posted = card.find('span', 's-time').text.replace('Â·', '').strip()\n",
    "        description = card.find('p', 's-desc').text.strip()\n",
    "        raw_link = card.find('a').get('href')\n",
    "        unquoted_link = requests.utils.unquote(raw_link)\n",
    "        pattern = re.compile(r'RU=(.+)\\/RK')\n",
    "        clean_link = re.search(pattern, unquoted_link).group(1)\n",
    "\n",
    "        article = (headline, source, posted, description, clean_link)\n",
    "        return article\n",
    "\n",
    "    def get_the_news(self, query):\n",
    "        \"\"\"Run the main program\"\"\"\n",
    "        article_headers = ['title', 'outlet', 'uploaded', 'description', 'url']\n",
    "\n",
    "        template = 'https://news.search.yahoo.com/search?p={}'\n",
    "        url = template.format(query)\n",
    "        articles = []\n",
    "        links = set()\n",
    "\n",
    "        while True:\n",
    "            response = requests.get(url, headers=headers)\n",
    "            soup = BeautifulSoup(response.text, 'html.parser')\n",
    "            cards = soup.find_all('div', 'NewsArticle')\n",
    "\n",
    "            # extract articles from page\n",
    "            for card in cards:\n",
    "                article = self.get_article(card)\n",
    "                link = article[-1]\n",
    "                if not link in links:\n",
    "                    links.add(link)\n",
    "                    articles.append(article)\n",
    "\n",
    "                    # find the next page\n",
    "            try:\n",
    "                url = soup.find('a', 'next').get('href')\n",
    "                sleep(1)\n",
    "            except AttributeError:\n",
    "                break\n",
    "\n",
    "        all_articles = pd.DataFrame(articles, columns=article_headers)\n",
    "\n",
    "        # for article in all_articles:\n",
    "        #    if article.uploaded\n",
    "\n",
    "        return all_articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ArticleCleaner():\n",
    "    \"\"\"\n",
    "    Functionality for importing and cleaning news articles\n",
    "    \"\"\"\n",
    "\n",
    "    def import_json(self, fetched_json_file):\n",
    "        # Import json and normalize data\n",
    "        df = pd.read_json(fetched_json_file)\n",
    "        norm_articles = pd.json_normalize(df['articles'])\n",
    "\n",
    "        return norm_articles\n",
    "\n",
    "    def clean_article(self, article):\n",
    "        \n",
    "        return ' '.join(re.sub(\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\", \" \", article).split())\n",
    "\n",
    "    def create_article(self, articles):\n",
    "        article = articles[['author', 'title', 'description', 'url', 'source.name', 'publishedAt']]\n",
    "        outlet = articles[['source.id', 'source.name']]\n",
    "\n",
    "        return article, outlet\n",
    "    \n",
    "    def get_recent_articles(self, all_articles):\n",
    "        recent_articles = pd.DataFrame()\n",
    "\n",
    "        for index, row in all_articles.iterrows():\n",
    "            if 'hour' in row.uploaded:\n",
    "                recent_articles = recent_articles.append(row)\n",
    "\n",
    "            if 'minute' in row.uploaded:\n",
    "                recent_articles = recent_articles.append(row)\n",
    "\n",
    "            if 'second' in row.uploaded:\n",
    "                recent_articles = recent_articles.append(row)\n",
    "\n",
    "        time = []\n",
    "        hours = recent_articles['uploaded'].str.split(' ')\n",
    "        df = pd.DataFrame(hours.values.tolist(), index=hours.index)\n",
    "        hours_ago = df[0]\n",
    "\n",
    "        for index, hours in hours_ago.items():\n",
    "            if int(hours) < 24:\n",
    "                d = datetime.today() - timedelta(hours=int(hours), minutes=0)\n",
    "                time.append(d.strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "            else:\n",
    "                d = datetime.today() - timedelta(hours=0, minutes=int(hours))\n",
    "                time.append(d.strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "        \n",
    "        recent_articles['publishedAt'] = time\n",
    "        #recent_articles = recent_articles.drop(['uploaded'])\n",
    "\n",
    "        return recent_articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentimentAnalyzer():\n",
    "    \"\"\"\n",
    "    Functionality for analyzing headlines sentiment\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.data = pd.read_csv('./datasets/headlines_labelled.txt',\n",
    "                        sep='\\t', header= None)\n",
    "        \n",
    "        # New words and values\n",
    "        self.new_words = {\n",
    "            'crushes': 10,\n",
    "            'beats': 5,\n",
    "            'misses': -5,\n",
    "            'trouble': -10,\n",
    "            'falls': -100,\n",
    "            'slides': -50,\n",
    "            'slide': -50,\n",
    "            'record high': 15,\n",
    "            'low': -15,\n",
    "            'one week low': -30,\n",
    "            'worth more': 5,\n",
    "            'digital gold': 5,\n",
    "            'high': 15,\n",
    "            'cryptocurrency fund': 10,\n",
    "            'up': 5,\n",
    "            'soars': 70,\n",
    "            'rebound': 20,\n",
    "            'pullback': -40,\n",
    "            'slumps': -60,\n",
    "            'jumps': 50,\n",
    "            'record low': -100,\n",
    "            'soaring': 70,\n",
    "            'bearish': -50,\n",
    "            'bullish': 50,\n",
    "            'bulls': 10,\n",
    "            'bears' : -10,\n",
    "            'hodl': 10,\n",
    "            'pulls back': -40,\n",
    "            'selloff': -70,\n",
    "            'retrace': -70,\n",
    "            'drop': -50,\n",
    "            'buying': 10,\n",
    "            'selling': -10,\n",
    "            'rally': 15,\n",
    "            'bounces': 20,\n",
    "            'testing support': -5,\n",
    "            'climb': 5,\n",
    "            'rise': 20,\n",
    "            'crashes': -100,\n",
    "            'crash': -100,\n",
    "            'downward': -30,\n",
    "            'plunges': -100,\n",
    "            'plunge' : -80,\n",
    "            'cardano': 0,\n",
    "            'descends': -30,\n",
    "            'descend': -30,\n",
    "            'gain' : 20,\n",
    "            'gains' : 20,\n",
    "            'worst' : -25,\n",
    "            'loss' : -15,\n",
    "            'without risk': 10,\n",
    "            'tumbles': -50,\n",
    "            'jeopardy': -50\n",
    "        }\n",
    "        \n",
    "        \n",
    "    def reading_dataset(self):\n",
    "        columnName = ['Headlines','Sentiment']\n",
    "        self.data.columns = columnName\n",
    "        self.data.head()\n",
    "        \n",
    "        return self.data\n",
    "    \n",
    "    \n",
    "    def analyze_test_headlines(self):        \n",
    "        # Instantiate the sentiment intensity analyzer with the existing lexicon\n",
    "        vader = SentimentIntensityAnalyzer()\n",
    "        \n",
    "        # Update the lexicon\n",
    "        vader.lexicon.update(self.new_words)\n",
    "        \n",
    "        data = self.reading_dataset()\n",
    "        \n",
    "        # Iterate through the headlines and get the polarity scores\n",
    "        scores = data['Headlines'].apply(vader.polarity_scores)\n",
    "        \n",
    "        # Convert the list of dicts into a DataFrame\n",
    "        scores_df = pd.DataFrame.from_records(scores)\n",
    "\n",
    "        # Join the DataFrames\n",
    "        scored_news = data.join(scores_df)\n",
    "        \n",
    "        scored_news['assigned_label'] = scored_news['Sentiment'].apply(lambda Sentiment: 'pos' if Sentiment>0 else 'neg')\n",
    "        scored_news['predicted_label'] = scored_news['compound'].apply(lambda compound: 'pos' if compound>=0 else 'neg')\n",
    "        \n",
    "        return scored_news\n",
    "    \n",
    "    def analyze_recent_headlines(self, data):     \n",
    "        scores_df = pd.DataFrame()\n",
    "        # Instantiate the sentiment intensity analyzer with the existing lexicon\n",
    "        vader = SentimentIntensityAnalyzer()\n",
    "        \n",
    "        # Update the lexicon\n",
    "        vader.lexicon.update(self.new_words)\n",
    "        \n",
    "        # Iterate through the headlines and get the polarity scores\n",
    "        #scores = data['clean_title'].apply(vader.polarity_scores)\n",
    "        \n",
    "        scores_df['neg'] = [vader.polarity_scores(x)['neg'] for x in data['clean_title']]\n",
    "        scores_df['neu'] = [vader.polarity_scores(x)['neu'] for x in data['clean_title']]\n",
    "        scores_df['pos'] = [vader.polarity_scores(x)['pos'] for x in data['clean_title']]\n",
    "        scores_df['compound'] = [vader.polarity_scores(x)['compound'] for x in data['clean_title']]\n",
    "        \n",
    "        # Convert the list of dicts into a DataFrame\n",
    "        #scores_df = pd.DataFrame.from_records(scores)\n",
    "\n",
    "        # Join the DataFrames\n",
    "        data = data.reset_index()\n",
    "        scored_news = data.merge(scores_df,left_index=True, right_index=True, how='inner')\n",
    "        \n",
    "        scored_news['predicted_label'] = scored_news['compound'].apply(lambda compound: 'pos' if compound > 0 else ('neu' if compound == 0 else 'neg'))\n",
    "        \n",
    "        return scored_news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PriceStreamer:\n",
    "    \"\"\"\n",
    "    Functionality for constantly streaming BTC price\n",
    "    \"\"\"\n",
    "    def parse_price():\n",
    "        res = requests.get('https://finance.yahoo.com/quote/BTC-USD?p=BTC-USD&.tsrc=fin-srch')\n",
    "        soup = bs4.BeautifulSoup(res.text, 'lxml')\n",
    "\n",
    "        price = soup.find_all('span', class_='Trsdu(0.3s) Fw(b) Fz(36px) Mb(-4px) D(ib)')[0].text\n",
    "        price_change = soup.find_all('span', class_='Trsdu(0.3s) Fw(500) Pstart(10px) Fz(24px) C($positiveColor)')[0].text\n",
    "\n",
    "        return price, price_change\n",
    "    \n",
    "    def get_hist_data():\n",
    "        cryptocurrencies = ['BTC-USD', 'ETH-USD', 'ADA-USD']\n",
    "        yahoo_financials_cryptocurrencies = YahooFinancials(cryptocurrencies)\n",
    "\n",
    "        d6 = (datetime.date.today() - datetime.timedelta(days=6)).strftime(\"%Y-%m-%d\")\n",
    "        d13 = (datetime.date.today() - datetime.timedelta(days=13)).strftime(\"%Y-%m-%d\")\n",
    "\n",
    "        daily_crypto_prices = yahoo_financials_cryptocurrencies.get_historical_price_data(d13, d6, 'daily')\n",
    "        data = pd.DataFrame.from_records(daily_crypto_prices)\n",
    "        price_df = pd.json_normalize(data['BTC-USD']['prices'])\n",
    "        \n",
    "        return price_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TradeCalls:\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    \n",
    "    def trade_call():\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    query = 'cryptocurrency'\n",
    "    headers = {\n",
    "        'accept': '*/*',\n",
    "        'accept-encoding': 'gzip, deflate, br',\n",
    "        'accept-language': 'en-US,en;q=0.9',\n",
    "        'referer': 'https://www.google.com',\n",
    "        'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/85.0.4183.83 Safari/537.36 Edg/85.0.564.44'\n",
    "    }\n",
    "    date = datetime.today().strftime(\"%Y%m%d\")\n",
    "    todays_date = datetime.today().strftime(\"%Y-%m-%d\")\n",
    "    yesterdays_date = (datetime.today() - timedelta(days=1)).strftime(\"%Y-%m-%d\")\n",
    "\n",
    "    article_cleaner = ArticleCleaner()\n",
    "    yahoo_article_streamer = YahooArticleStreamer()\n",
    "    \n",
    "    news_api_streamer = NewsAPIArticleStreamer()\n",
    "    news_api_cleaner = NewsAPIArticleCleaner()\n",
    "    \n",
    "    sentiment_analyzer = SentimentAnalyzer()\n",
    "\n",
    "    news_api_articles = news_api_streamer.stream_articles(query, yesterdays_date, todays_date)\n",
    "    yahoo_articles = yahoo_article_streamer.get_the_news(query)\n",
    "        \n",
    "    news_article_data = pd.json_normalize(news_api_articles['articles'])\n",
    "    news_api_df, outlets = article_cleaner.create_article(news_article_data)\n",
    "    news_api_df['publishedAt'] = pd.to_datetime(news_api_df['publishedAt'], infer_datetime_format=True)\n",
    "    \n",
    "    yahoo_clean_title = np.array([article_cleaner.clean_article(article) for article in yahoo_articles['title']])\n",
    "    yahoo_clean_desc = np.array([article_cleaner.clean_article(article) for article in yahoo_articles['description']])\n",
    "    \n",
    "    news_api_clean_title = np.array([article_cleaner.clean_article(article) for article in news_api_df['title']])\n",
    "    news_api_clean_desc = np.array([article_cleaner.clean_article(article) for article in news_api_df['description']])\n",
    "    \n",
    "    yahoo_articles['clean_title'] = yahoo_clean_title\n",
    "    yahoo_articles['clean_description'] = yahoo_clean_desc\n",
    "    \n",
    "    news_api_df['clean_title'] = news_api_clean_title\n",
    "    news_api_df['clean_description'] = news_api_clean_desc\n",
    "    \n",
    "    recent_yahoo_articles = article_cleaner.get_recent_articles(yahoo_articles)\n",
    "    \n",
    "    all_headlines = recent_yahoo_articles[['publishedAt','clean_title']]\n",
    "    all_headlines = all_headlines.append(news_api_df[['publishedAt','clean_title']])\n",
    "\n",
    "    scored_headlines = sentiment_analyzer.analyze_recent_headlines(all_headlines)\n",
    "    \n",
    "    high_headlines = scored_headlines[(scored_headlines['compound'] > .5) | (scored_headlines['compound'] < -0.5)]\n",
    "    \n",
    "    high_headlines['date'] = pd.to_datetime(high_headlines['publishedAt'], format='%Y-%m-%d')\n",
    "    high_headlines['date'] = high_headlines['date'].dt.strftime('%Y-%m-%d')\n",
    "    \n",
    "    high_headlines = high_headlines.drop(columns=['index'])\n",
    "    \n",
    "    #high_headlines.to_csv(f'.\\{date}sentiment.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>publishedAt</th>\n",
       "      <th>clean_title</th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "      <th>pos</th>\n",
       "      <th>compound</th>\n",
       "      <th>predicted_label</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-01-26 14:28:22</td>\n",
       "      <td>Smart Money Buying Crypto as Harvard Said to B...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.396</td>\n",
       "      <td>0.604</td>\n",
       "      <td>0.9493</td>\n",
       "      <td>pos</td>\n",
       "      <td>2021-01-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2021-01-26 11:06:22</td>\n",
       "      <td>Bitcoin made up 97 of total crypto inflows in ...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.400</td>\n",
       "      <td>0.7906</td>\n",
       "      <td>pos</td>\n",
       "      <td>2021-01-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2021-01-26 10:06:22</td>\n",
       "      <td>Ripple Has Become a Cryptocurrency Only for In...</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.6597</td>\n",
       "      <td>neg</td>\n",
       "      <td>2021-01-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2021-01-26 02:06:22</td>\n",
       "      <td>Harvard and Yale Endowments Among Those Report...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.421</td>\n",
       "      <td>0.579</td>\n",
       "      <td>0.9325</td>\n",
       "      <td>pos</td>\n",
       "      <td>2021-01-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2021-01-26 03:06:22</td>\n",
       "      <td>A bitcoin IRA lets you profit from the cryptoc...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.295</td>\n",
       "      <td>0.705</td>\n",
       "      <td>0.9865</td>\n",
       "      <td>pos</td>\n",
       "      <td>2021-01-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2021-01-26 01:06:22</td>\n",
       "      <td>Bearish Divergence Hints At First Major Chainl...</td>\n",
       "      <td>0.864</td>\n",
       "      <td>0.136</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.9970</td>\n",
       "      <td>neg</td>\n",
       "      <td>2021-01-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2021-01-26 05:06:22</td>\n",
       "      <td>Litecoin Falls 11 In Rout By Investing com</td>\n",
       "      <td>0.935</td>\n",
       "      <td>0.065</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.9993</td>\n",
       "      <td>neg</td>\n",
       "      <td>2021-01-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2021-01-26 09:06:22</td>\n",
       "      <td>Bitcoin BTC Continues to Struggle While Ethere...</td>\n",
       "      <td>0.073</td>\n",
       "      <td>0.348</td>\n",
       "      <td>0.579</td>\n",
       "      <td>0.9682</td>\n",
       "      <td>pos</td>\n",
       "      <td>2021-01-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>2021-01-26 05:06:22</td>\n",
       "      <td>Bitcoin Falls 10 18 In Bearish Trade</td>\n",
       "      <td>0.968</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.9997</td>\n",
       "      <td>neg</td>\n",
       "      <td>2021-01-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>2021-01-26 05:06:22</td>\n",
       "      <td>Litecoin Falls 10 05 In Selloff</td>\n",
       "      <td>0.977</td>\n",
       "      <td>0.023</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.9997</td>\n",
       "      <td>neg</td>\n",
       "      <td>2021-01-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>2021-01-26 05:06:22</td>\n",
       "      <td>BitIRA 2020 Retrospective Retirement Funds Soa...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.073</td>\n",
       "      <td>0.927</td>\n",
       "      <td>0.9986</td>\n",
       "      <td>pos</td>\n",
       "      <td>2021-01-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>2021-01-26 14:42:22</td>\n",
       "      <td>Crypto Markets Show More Signs of Excess Amid ...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.300</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.9818</td>\n",
       "      <td>pos</td>\n",
       "      <td>2021-01-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>2021-01-25 16:06:22</td>\n",
       "      <td>I ve been convinced to buy Bitcoin the odds ar...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.641</td>\n",
       "      <td>0.359</td>\n",
       "      <td>0.6808</td>\n",
       "      <td>pos</td>\n",
       "      <td>2021-01-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>2021-01-25 19:06:22</td>\n",
       "      <td>Grayscale Gifts 1 Million To Coin Center Will ...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.400</td>\n",
       "      <td>0.7906</td>\n",
       "      <td>pos</td>\n",
       "      <td>2021-01-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>2021-01-25 21:06:22</td>\n",
       "      <td>Crypto Hedge Funds Underperformed Bitcoin Duri...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.333</td>\n",
       "      <td>0.667</td>\n",
       "      <td>0.9682</td>\n",
       "      <td>pos</td>\n",
       "      <td>2021-01-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>2021-01-25 19:06:22</td>\n",
       "      <td>Marathon Patent Is Not a Wise Play Even for Cr...</td>\n",
       "      <td>0.203</td>\n",
       "      <td>0.310</td>\n",
       "      <td>0.487</td>\n",
       "      <td>0.8862</td>\n",
       "      <td>pos</td>\n",
       "      <td>2021-01-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>2021-01-25 21:06:22</td>\n",
       "      <td>Harvard Yale Brown Endowments Have Been Buying...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.522</td>\n",
       "      <td>0.478</td>\n",
       "      <td>0.9325</td>\n",
       "      <td>pos</td>\n",
       "      <td>2021-01-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>2021-01-26 13:06:22</td>\n",
       "      <td>Trouble for Bitcoin as 3 On Chain Indicators P...</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.9325</td>\n",
       "      <td>neg</td>\n",
       "      <td>2021-01-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>2021-01-26 05:06:22</td>\n",
       "      <td>Dow Jones Today Stocks Ticks Higher As Earning...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.802</td>\n",
       "      <td>0.198</td>\n",
       "      <td>0.5719</td>\n",
       "      <td>pos</td>\n",
       "      <td>2021-01-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>2021-01-26 14:39:22</td>\n",
       "      <td>S P 500 hits record high as investors prepare ...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.407</td>\n",
       "      <td>0.593</td>\n",
       "      <td>0.9682</td>\n",
       "      <td>pos</td>\n",
       "      <td>2021-01-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>2021-01-26 07:06:22</td>\n",
       "      <td>FOREX Dollar gains as stimulus nerves nudge in...</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.217</td>\n",
       "      <td>0.739</td>\n",
       "      <td>0.9840</td>\n",
       "      <td>pos</td>\n",
       "      <td>2021-01-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>2021-01-26 05:06:22</td>\n",
       "      <td>FOREX Dollar gains as stimulus nerves nudge in...</td>\n",
       "      <td>0.041</td>\n",
       "      <td>0.263</td>\n",
       "      <td>0.696</td>\n",
       "      <td>0.9840</td>\n",
       "      <td>pos</td>\n",
       "      <td>2021-01-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>2021-01-26 05:06:22</td>\n",
       "      <td>FOREX Dollar gains as stimulus nerves nudge in...</td>\n",
       "      <td>0.041</td>\n",
       "      <td>0.263</td>\n",
       "      <td>0.696</td>\n",
       "      <td>0.9840</td>\n",
       "      <td>pos</td>\n",
       "      <td>2021-01-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>2021-01-25 21:06:22</td>\n",
       "      <td>Harvard Yale Brown Endowments Have Been Buying...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.542</td>\n",
       "      <td>0.458</td>\n",
       "      <td>0.9325</td>\n",
       "      <td>pos</td>\n",
       "      <td>2021-01-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>2021-01-26 01:06:22</td>\n",
       "      <td>Warning Signal the messaging app s new feature...</td>\n",
       "      <td>0.353</td>\n",
       "      <td>0.647</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.5994</td>\n",
       "      <td>neg</td>\n",
       "      <td>2021-01-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>2021-01-25 20:06:22</td>\n",
       "      <td>Substack Newsletters Are Being Used to Spread ...</td>\n",
       "      <td>0.322</td>\n",
       "      <td>0.678</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.5859</td>\n",
       "      <td>neg</td>\n",
       "      <td>2021-01-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>2021-01-25 16:06:22</td>\n",
       "      <td>Bitcoin Declines Are Buying Opportunities Says...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.340</td>\n",
       "      <td>0.660</td>\n",
       "      <td>0.9485</td>\n",
       "      <td>pos</td>\n",
       "      <td>2021-01-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>2021-01-26 05:06:22</td>\n",
       "      <td>FOREX Dollar gains as stimulus nerves nudge in...</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.217</td>\n",
       "      <td>0.739</td>\n",
       "      <td>0.9840</td>\n",
       "      <td>pos</td>\n",
       "      <td>2021-01-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>2021-01-26 10:06:22</td>\n",
       "      <td>These 5 charts show why Bitcoin price failed t...</td>\n",
       "      <td>0.268</td>\n",
       "      <td>0.732</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.5106</td>\n",
       "      <td>neg</td>\n",
       "      <td>2021-01-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>2021-01-26 13:06:22</td>\n",
       "      <td>American Express Beats As Trends Improve Sees ...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.459</td>\n",
       "      <td>0.541</td>\n",
       "      <td>0.9153</td>\n",
       "      <td>pos</td>\n",
       "      <td>2021-01-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>2021-01-26 07:06:22</td>\n",
       "      <td>Signal is drama free for now but it should pre...</td>\n",
       "      <td>0.745</td>\n",
       "      <td>0.213</td>\n",
       "      <td>0.042</td>\n",
       "      <td>-0.9944</td>\n",
       "      <td>neg</td>\n",
       "      <td>2021-01-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>2021-01-25 17:06:22</td>\n",
       "      <td>RTX 3080 Mining Rig in a BMW s Trunk Meant Jus...</td>\n",
       "      <td>0.306</td>\n",
       "      <td>0.694</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.5267</td>\n",
       "      <td>neg</td>\n",
       "      <td>2021-01-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>2021-01-26 14:42:22</td>\n",
       "      <td>Crypto Markets Show More Signs of Excess Amid ...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.300</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.9818</td>\n",
       "      <td>pos</td>\n",
       "      <td>2021-01-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>2021-01-26 07:07:40</td>\n",
       "      <td>Signal is drama free for now but it should pre...</td>\n",
       "      <td>0.745</td>\n",
       "      <td>0.213</td>\n",
       "      <td>0.042</td>\n",
       "      <td>-0.9944</td>\n",
       "      <td>neg</td>\n",
       "      <td>2021-01-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>2021-01-25 00:39:19</td>\n",
       "      <td>Ethereum s Ether Cryptocurrency Sets New All T...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.385</td>\n",
       "      <td>0.615</td>\n",
       "      <td>0.9682</td>\n",
       "      <td>pos</td>\n",
       "      <td>2021-01-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>2021-01-25 11:29:14</td>\n",
       "      <td>Big Investors Stacked up Ether as Price Rose t...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.290</td>\n",
       "      <td>0.710</td>\n",
       "      <td>0.9818</td>\n",
       "      <td>pos</td>\n",
       "      <td>2021-01-25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             publishedAt                                        clean_title  \\\n",
       "1    2021-01-26 14:28:22  Smart Money Buying Crypto as Harvard Said to B...   \n",
       "12   2021-01-26 11:06:22  Bitcoin made up 97 of total crypto inflows in ...   \n",
       "14   2021-01-26 10:06:22  Ripple Has Become a Cryptocurrency Only for In...   \n",
       "18   2021-01-26 02:06:22  Harvard and Yale Endowments Among Those Report...   \n",
       "24   2021-01-26 03:06:22  A bitcoin IRA lets you profit from the cryptoc...   \n",
       "28   2021-01-26 01:06:22  Bearish Divergence Hints At First Major Chainl...   \n",
       "29   2021-01-26 05:06:22         Litecoin Falls 11 In Rout By Investing com   \n",
       "30   2021-01-26 09:06:22  Bitcoin BTC Continues to Struggle While Ethere...   \n",
       "31   2021-01-26 05:06:22               Bitcoin Falls 10 18 In Bearish Trade   \n",
       "33   2021-01-26 05:06:22                    Litecoin Falls 10 05 In Selloff   \n",
       "43   2021-01-26 05:06:22  BitIRA 2020 Retrospective Retirement Funds Soa...   \n",
       "49   2021-01-26 14:42:22  Crypto Markets Show More Signs of Excess Amid ...   \n",
       "54   2021-01-25 16:06:22  I ve been convinced to buy Bitcoin the odds ar...   \n",
       "55   2021-01-25 19:06:22  Grayscale Gifts 1 Million To Coin Center Will ...   \n",
       "60   2021-01-25 21:06:22  Crypto Hedge Funds Underperformed Bitcoin Duri...   \n",
       "61   2021-01-25 19:06:22  Marathon Patent Is Not a Wise Play Even for Cr...   \n",
       "63   2021-01-25 21:06:22  Harvard Yale Brown Endowments Have Been Buying...   \n",
       "64   2021-01-26 13:06:22  Trouble for Bitcoin as 3 On Chain Indicators P...   \n",
       "65   2021-01-26 05:06:22  Dow Jones Today Stocks Ticks Higher As Earning...   \n",
       "66   2021-01-26 14:39:22  S P 500 hits record high as investors prepare ...   \n",
       "79   2021-01-26 07:06:22  FOREX Dollar gains as stimulus nerves nudge in...   \n",
       "82   2021-01-26 05:06:22  FOREX Dollar gains as stimulus nerves nudge in...   \n",
       "83   2021-01-26 05:06:22  FOREX Dollar gains as stimulus nerves nudge in...   \n",
       "92   2021-01-25 21:06:22  Harvard Yale Brown Endowments Have Been Buying...   \n",
       "93   2021-01-26 01:06:22  Warning Signal the messaging app s new feature...   \n",
       "96   2021-01-25 20:06:22  Substack Newsletters Are Being Used to Spread ...   \n",
       "97   2021-01-25 16:06:22  Bitcoin Declines Are Buying Opportunities Says...   \n",
       "100  2021-01-26 05:06:22  FOREX Dollar gains as stimulus nerves nudge in...   \n",
       "101  2021-01-26 10:06:22  These 5 charts show why Bitcoin price failed t...   \n",
       "104  2021-01-26 13:06:22  American Express Beats As Trends Improve Sees ...   \n",
       "107  2021-01-26 07:06:22  Signal is drama free for now but it should pre...   \n",
       "116  2021-01-25 17:06:22  RTX 3080 Mining Rig in a BMW s Trunk Meant Jus...   \n",
       "118  2021-01-26 14:42:22  Crypto Markets Show More Signs of Excess Amid ...   \n",
       "126  2021-01-26 07:07:40  Signal is drama free for now but it should pre...   \n",
       "138  2021-01-25 00:39:19  Ethereum s Ether Cryptocurrency Sets New All T...   \n",
       "139  2021-01-25 11:29:14  Big Investors Stacked up Ether as Price Rose t...   \n",
       "\n",
       "       neg    neu    pos  compound predicted_label        date  \n",
       "1    0.000  0.396  0.604    0.9493             pos  2021-01-26  \n",
       "12   0.000  0.600  0.400    0.7906             pos  2021-01-26  \n",
       "14   0.375  0.625  0.000   -0.6597             neg  2021-01-26  \n",
       "18   0.000  0.421  0.579    0.9325             pos  2021-01-26  \n",
       "24   0.000  0.295  0.705    0.9865             pos  2021-01-26  \n",
       "28   0.864  0.136  0.000   -0.9970             neg  2021-01-26  \n",
       "29   0.935  0.065  0.000   -0.9993             neg  2021-01-26  \n",
       "30   0.073  0.348  0.579    0.9682             pos  2021-01-26  \n",
       "31   0.968  0.032  0.000   -0.9997             neg  2021-01-26  \n",
       "33   0.977  0.023  0.000   -0.9997             neg  2021-01-26  \n",
       "43   0.000  0.073  0.927    0.9986             pos  2021-01-26  \n",
       "49   0.000  0.300  0.700    0.9818             pos  2021-01-26  \n",
       "54   0.000  0.641  0.359    0.6808             pos  2021-01-25  \n",
       "55   0.000  0.600  0.400    0.7906             pos  2021-01-25  \n",
       "60   0.000  0.333  0.667    0.9682             pos  2021-01-25  \n",
       "61   0.203  0.310  0.487    0.8862             pos  2021-01-25  \n",
       "63   0.000  0.522  0.478    0.9325             pos  2021-01-25  \n",
       "64   0.500  0.500  0.000   -0.9325             neg  2021-01-26  \n",
       "65   0.000  0.802  0.198    0.5719             pos  2021-01-26  \n",
       "66   0.000  0.407  0.593    0.9682             pos  2021-01-26  \n",
       "79   0.043  0.217  0.739    0.9840             pos  2021-01-26  \n",
       "82   0.041  0.263  0.696    0.9840             pos  2021-01-26  \n",
       "83   0.041  0.263  0.696    0.9840             pos  2021-01-26  \n",
       "92   0.000  0.542  0.458    0.9325             pos  2021-01-25  \n",
       "93   0.353  0.647  0.000   -0.5994             neg  2021-01-26  \n",
       "96   0.322  0.678  0.000   -0.5859             neg  2021-01-25  \n",
       "97   0.000  0.340  0.660    0.9485             pos  2021-01-25  \n",
       "100  0.043  0.217  0.739    0.9840             pos  2021-01-26  \n",
       "101  0.268  0.732  0.000   -0.5106             neg  2021-01-26  \n",
       "104  0.000  0.459  0.541    0.9153             pos  2021-01-26  \n",
       "107  0.745  0.213  0.042   -0.9944             neg  2021-01-26  \n",
       "116  0.306  0.694  0.000   -0.5267             neg  2021-01-25  \n",
       "118  0.000  0.300  0.700    0.9818             pos  2021-01-26  \n",
       "126  0.745  0.213  0.042   -0.9944             neg  2021-01-26  \n",
       "138  0.000  0.385  0.615    0.9682             pos  2021-01-25  \n",
       "139  0.000  0.290  0.710    0.9818             pos  2021-01-25  "
      ]
     },
     "execution_count": 470,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "high_headlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_headlines['compound'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_dates = high_headlines['date'].unique()\n",
    "grouped_dates = high_headlines.groupby(['date'])\n",
    "keys_dates = list(grouped_dates.groups.keys())\n",
    "\n",
    "max_cs = []\n",
    "min_cs = []\n",
    "\n",
    "for key in grouped_dates.groups.keys():\n",
    "    data = grouped_dates.get_group(key)\n",
    "    if data[\"compound\"].max() > 0:\n",
    "        max_cs.append(data[\"compound\"].max())\n",
    "    elif data[\"compound\"].max() < 0:\n",
    "        max_cs.append(0)\n",
    "    \n",
    "    if data[\"compound\"].min() < 0:\n",
    "        min_cs.append(data[\"compound\"].min())\n",
    "    elif data[\"compound\"].min() > 0:\n",
    "        min_cs.append(0)\n",
    "    \n",
    "extreme_scores_dict = {'Date':keys_dates,'max_scores':max_cs,'min_scores':min_cs}\n",
    "extreme_scores_df = pd.DataFrame(extreme_scores_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>max_scores</th>\n",
       "      <th>min_scores</th>\n",
       "      <th>final_scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-01-25</td>\n",
       "      <td>0.9818</td>\n",
       "      <td>-0.8126</td>\n",
       "      <td>0.1692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-01-26</td>\n",
       "      <td>0.9986</td>\n",
       "      <td>-0.9970</td>\n",
       "      <td>0.0016</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date  max_scores  min_scores  final_scores\n",
       "0  2021-01-25      0.9818     -0.8126        0.1692\n",
       "1  2021-01-26      0.9986     -0.9970        0.0016"
      ]
     },
     "execution_count": 458,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_scores = []\n",
    "for i in range(len(extreme_scores_df)):\n",
    "    final_scores.append(extreme_scores_df['max_scores'].values[i] + extreme_scores_df['min_scores'].values[i])\n",
    "\n",
    "extreme_scores_df['final_scores'] = final_scores\n",
    "\n",
    "extreme_scores_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trade Call for 2021-01-25 is Buy.\n",
      "Trade Call for 2021-01-26 is Buy.\n"
     ]
    }
   ],
   "source": [
    "# VADER trade calls\n",
    "sentiment_Buy=[]\n",
    "sentiment_Sell=[]\n",
    "for i in range(len(extreme_scores_df)):\n",
    "    row=extreme_scores_df['Date'].iloc[i]\n",
    "    \n",
    "    if extreme_scores_df['final_scores'].values[i] > 0:\n",
    "        print(f\"Trade Call for {row} is Buy.\")\n",
    "        sentiment_Buy.append(extreme_scores_df['Date'].iloc[i])\n",
    "    elif extreme_scores_df['final_scores'].values[i] < 0:\n",
    "        print(f\"Trade Call for {row} is Sell.\")\n",
    "        sentiment_Sell.append(extreme_scores_df['Date'].iloc[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2021-01-26']"
      ]
     },
     "execution_count": 434,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_Sell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
