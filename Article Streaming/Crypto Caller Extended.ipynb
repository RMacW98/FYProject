{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import csv\n",
    "from time import sleep\n",
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import bs4\n",
    "from bs4 import BeautifulSoup\n",
    "import datetime\n",
    "from datetime import datetime, timedelta, date\n",
    "\n",
    "import pandas_datareader as pdr\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from newsapi import NewsApiClient\n",
    "from yahoofinancials import YahooFinancials\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # # NEWS API AUTHENTICATER # # # #\n",
    "class NewsAuthenticator():\n",
    "\n",
    "    def authenticate_news_api(self):\n",
    "        auth = NewsApiClient(api_key='cc3f4e3191f149658f3922e9c47ec1ad')\n",
    "        return auth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # # NEWS API STREAMER # # # #\n",
    "class NewsAPIArticleStreamer():\n",
    "    \"\"\"\n",
    "    Class for streaming and processing articles daily\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.news_authenticator = NewsAuthenticator()    \n",
    "\n",
    "    def stream_articles(self, query, from_param, to):\n",
    "        # This handles Twitter authetification and the connection to Twitter Streaming API\n",
    "        newsapi = self.news_authenticator.authenticate_news_api()\n",
    "        all_articles = newsapi.get_everything(q=query,\n",
    "                                          from_param= from_param,\n",
    "                                          to= to,\n",
    "                                          language='en')\n",
    "        \n",
    "        return all_articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NewsAPIArticleCleaner():\n",
    "    \"\"\"\n",
    "    Functionality for importing and cleaning news articles\n",
    "    \"\"\"\n",
    "    def import_json(self, fetched_json_file):\n",
    "        # Import json and normalize data\n",
    "        df = pd.read_json(fetched_json_file)\n",
    "        norm_articles = pd.json_normalize(df['articles'])\n",
    "        \n",
    "        return norm_articles\n",
    "\n",
    "    def clean_article(self, article):\n",
    "        return ' '.join(re.sub(\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\", \" \", article).split())\n",
    "    \n",
    "    def create_article(self, articles):\n",
    "        article = articles[['author', 'title', 'description', 'url', 'source.name', 'publishedAt']]\n",
    "        article['publishedAt'] = pd.to_datetime(article['publishedAt'], infer_datetime_format=True)\n",
    "        article.sort_values(by='publishedAt',inplace=True)\n",
    "        article = article.reset_index()\n",
    "        article = article.drop(['index'], axis=1)\n",
    "        \n",
    "        outlet = articles[['source.id', 'source.name']]\n",
    "        \n",
    "        return article, outlet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # # YAHOO FINANCE STREAMER # # # #\n",
    "class YahooArticleStreamer:\n",
    "    \"\"\"\n",
    "    Class for streaming and processing articles daily\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def get_article(self, card):\n",
    "        \"\"\"Extract article information from the raw html\"\"\"\n",
    "        headline = card.find('h4', 's-title').text\n",
    "        source = card.find(\"span\", 's-source').text\n",
    "        posted = card.find('span', 's-time').text.replace('Â·', '').strip()\n",
    "        description = card.find('p', 's-desc').text.strip()\n",
    "        raw_link = card.find('a').get('href')\n",
    "        unquoted_link = requests.utils.unquote(raw_link)\n",
    "        pattern = re.compile(r'RU=(.+)\\/RK')\n",
    "        clean_link = re.search(pattern, unquoted_link).group(1)\n",
    "\n",
    "        article = (headline, source, posted, description, clean_link)\n",
    "        return article\n",
    "\n",
    "    def get_the_news(self, query):\n",
    "        \"\"\"Run the main program\"\"\"\n",
    "        article_headers = ['title', 'outlet', 'uploaded', 'description', 'url']\n",
    "\n",
    "        template = 'https://news.search.yahoo.com/search?p={}'\n",
    "        url = template.format(query)\n",
    "        articles = []\n",
    "        links = set()\n",
    "\n",
    "        while True:\n",
    "            response = requests.get(url, headers=headers)\n",
    "            soup = BeautifulSoup(response.text, 'html.parser')\n",
    "            cards = soup.find_all('div', 'NewsArticle')\n",
    "\n",
    "            # extract articles from page\n",
    "            for card in cards:\n",
    "                article = self.get_article(card)\n",
    "                link = article[-1]\n",
    "                if not link in links:\n",
    "                    links.add(link)\n",
    "                    articles.append(article)\n",
    "\n",
    "                    # find the next page\n",
    "            try:\n",
    "                url = soup.find('a', 'next').get('href')\n",
    "                sleep(1)\n",
    "            except AttributeError:\n",
    "                break\n",
    "\n",
    "        all_articles = pd.DataFrame(articles, columns=article_headers)\n",
    "\n",
    "        # for article in all_articles:\n",
    "        #    if article.uploaded\n",
    "\n",
    "        return all_articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ArticleCleaner():\n",
    "    \"\"\"\n",
    "    Functionality for importing and cleaning news articles\n",
    "    \"\"\"\n",
    "\n",
    "    def import_json(self, fetched_json_file):\n",
    "        # Import json and normalize data\n",
    "        df = pd.read_json(fetched_json_file)\n",
    "        norm_articles = pd.json_normalize(df['articles'])\n",
    "\n",
    "        return norm_articles\n",
    "\n",
    "    def clean_article(self, article):\n",
    "        \n",
    "        return ' '.join(re.sub(\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\", \" \", article).split())\n",
    "\n",
    "    def create_article(self, articles):\n",
    "        article = articles[['author', 'title', 'description', 'url', 'source.name', 'publishedAt']]\n",
    "        outlet = articles[['source.id', 'source.name']]\n",
    "\n",
    "        return article, outlet\n",
    "    \n",
    "    def get_recent_articles(self, all_articles):\n",
    "        recent_articles = pd.DataFrame()\n",
    "\n",
    "        for index, row in all_articles.iterrows():\n",
    "            if 'hour' in row.uploaded:\n",
    "                recent_articles = recent_articles.append(row)\n",
    "\n",
    "            if 'minute' in row.uploaded:\n",
    "                recent_articles = recent_articles.append(row)\n",
    "\n",
    "            if 'second' in row.uploaded:\n",
    "                recent_articles = recent_articles.append(row)\n",
    "\n",
    "        time = []\n",
    "        hours = recent_articles['uploaded'].str.split(' ')\n",
    "        df = pd.DataFrame(hours.values.tolist(), index=hours.index)\n",
    "        hours_ago = df[0]\n",
    "\n",
    "        for index, hours in hours_ago.items():\n",
    "            if int(hours) < 24:\n",
    "                d = datetime.today() - timedelta(hours=int(hours), minutes=0)\n",
    "                time.append(d.strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "            else:\n",
    "                d = datetime.today() - timedelta(hours=0, minutes=int(hours))\n",
    "                time.append(d.strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "        \n",
    "        recent_articles['publishedAt'] = time\n",
    "        #recent_articles = recent_articles.drop(['uploaded'])\n",
    "\n",
    "        return recent_articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentimentAnalyzer():\n",
    "    \"\"\"\n",
    "    Functionality for analyzing headlines sentiment\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.data = pd.read_csv('./datasets/headlines_labelled.txt',\n",
    "                        sep='\\t', header= None)\n",
    "        \n",
    "        # New words and values\n",
    "        self.new_words = {\n",
    "            'crushes': 10,\n",
    "            'beats': 5,\n",
    "            'misses': -5,\n",
    "            'trouble': -10,\n",
    "            'falls': -100,\n",
    "            'slides': -50,\n",
    "            'slide': -50,\n",
    "            'record high': 15,\n",
    "            'low': -15,\n",
    "            'one week low': -30,\n",
    "            'worth more': 5,\n",
    "            'digital gold': 5,\n",
    "            'high': 15,\n",
    "            'cryptocurrency fund': 10,\n",
    "            'up': 5,\n",
    "            'soars': 70,\n",
    "            'rebound': 20,\n",
    "            'pullback': -40,\n",
    "            'slumps': -60,\n",
    "            'jumps': 50,\n",
    "            'record low': -100,\n",
    "            'soaring': 70,\n",
    "            'bearish': -50,\n",
    "            'bullish': 50,\n",
    "            'bulls': 10,\n",
    "            'bears' : -10,\n",
    "            'hodl': 10,\n",
    "            'pulls back': -40,\n",
    "            'selloff': -70,\n",
    "            'retrace': -70,\n",
    "            'drop': -50,\n",
    "            'buying': 10,\n",
    "            'selling': -10,\n",
    "            'rally': 15,\n",
    "            'bounces': 20,\n",
    "            'testing support': -5,\n",
    "            'climb': 5,\n",
    "            'rise': 20,\n",
    "            'crashes': -100,\n",
    "            'crash': -100,\n",
    "            'downward': -30,\n",
    "            'plunges': -100,\n",
    "            'plunge' : -80,\n",
    "            'cardano': 0,\n",
    "            'descends': -30,\n",
    "            'descend': -30,\n",
    "            'gain' : 20,\n",
    "            'gains' : 20,\n",
    "            'worst' : -25,\n",
    "            'loss' : -15,\n",
    "            'without risk': 10,\n",
    "            'tumbles': -50,\n",
    "            'jeopardy': -50\n",
    "        }\n",
    "        \n",
    "        \n",
    "    def reading_dataset(self):\n",
    "        columnName = ['Headlines','Sentiment']\n",
    "        self.data.columns = columnName\n",
    "        self.data.head()\n",
    "        \n",
    "        return self.data\n",
    "    \n",
    "    \n",
    "    def analyze_test_headlines(self):        \n",
    "        # Instantiate the sentiment intensity analyzer with the existing lexicon\n",
    "        vader = SentimentIntensityAnalyzer()\n",
    "        \n",
    "        # Update the lexicon\n",
    "        vader.lexicon.update(self.new_words)\n",
    "        \n",
    "        data = self.reading_dataset()\n",
    "        \n",
    "        # Iterate through the headlines and get the polarity scores\n",
    "        scores = data['Headlines'].apply(vader.polarity_scores)\n",
    "        \n",
    "        # Convert the list of dicts into a DataFrame\n",
    "        scores_df = pd.DataFrame.from_records(scores)\n",
    "\n",
    "        # Join the DataFrames\n",
    "        scored_news = data.join(scores_df)\n",
    "        \n",
    "        scored_news['assigned_label'] = scored_news['Sentiment'].apply(lambda Sentiment: 'pos' if Sentiment>0 else 'neg')\n",
    "        scored_news['predicted_label'] = scored_news['compound'].apply(lambda compound: 'pos' if compound>=0 else 'neg')\n",
    "        \n",
    "        return scored_news\n",
    "    \n",
    "    def analyze_recent_headlines(self, data):     \n",
    "        scores_df = pd.DataFrame()\n",
    "        # Instantiate the sentiment intensity analyzer with the existing lexicon\n",
    "        vader = SentimentIntensityAnalyzer()\n",
    "        \n",
    "        # Update the lexicon\n",
    "        vader.lexicon.update(self.new_words)\n",
    "        \n",
    "        # Iterate through the headlines and get the polarity scores\n",
    "        #scores = data['clean_title'].apply(vader.polarity_scores)\n",
    "        \n",
    "        scores_df['neg'] = [vader.polarity_scores(x)['neg'] for x in data['clean_title']]\n",
    "        scores_df['neu'] = [vader.polarity_scores(x)['neu'] for x in data['clean_title']]\n",
    "        scores_df['pos'] = [vader.polarity_scores(x)['pos'] for x in data['clean_title']]\n",
    "        scores_df['compound'] = [vader.polarity_scores(x)['compound'] for x in data['clean_title']]\n",
    "        \n",
    "        # Convert the list of dicts into a DataFrame\n",
    "        #scores_df = pd.DataFrame.from_records(scores)\n",
    "\n",
    "        # Join the DataFrames\n",
    "        data = data.reset_index()\n",
    "        scored_news = data.merge(scores_df,left_index=True, right_index=True, how='inner')\n",
    "        \n",
    "        scored_news['predicted_label'] = scored_news['compound'].apply(lambda compound: 'pos' if compound > 0 else ('neu' if compound == 0 else 'neg'))\n",
    "        \n",
    "        return scored_news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PriceStreamer():\n",
    "    \"\"\"\n",
    "    Functionality for constantly streaming BTC price\n",
    "    \"\"\"\n",
    "    def parse_price():\n",
    "        res = requests.get('https://finance.yahoo.com/quote/BTC-USD?p=BTC-USD&.tsrc=fin-srch')\n",
    "        soup = bs4.BeautifulSoup(res.text, 'lxml')\n",
    "\n",
    "        price = soup.find_all('span', class_='Trsdu(0.3s) Fw(b) Fz(36px) Mb(-4px) D(ib)')[0].text\n",
    "        price_change = soup.find_all('span', class_='Trsdu(0.3s) Fw(500) Pstart(10px) Fz(24px) C($positiveColor)')[0].text\n",
    "\n",
    "        return price, price_change\n",
    "    \n",
    "    def get_hist_data():\n",
    "        cryptocurrencies = ['BTC-USD', 'ETH-USD', 'ADA-USD']\n",
    "        yahoo_financials_cryptocurrencies = YahooFinancials(cryptocurrencies)\n",
    "\n",
    "        d6 = (datetime.date.today() - datetime.timedelta(days=6)).strftime(\"%Y-%m-%d\")\n",
    "        d13 = (datetime.date.today() - datetime.timedelta(days=13)).strftime(\"%Y-%m-%d\")\n",
    "\n",
    "        daily_crypto_prices = yahoo_financials_cryptocurrencies.get_historical_price_data(d13, d6, 'daily')\n",
    "        data = pd.DataFrame.from_records(daily_crypto_prices)\n",
    "        price_df = pd.json_normalize(data['BTC-USD']['prices'])\n",
    "        \n",
    "        return price_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-416-cdfc1be087f2>:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  news_api_df['publishedAt'] = pd.to_datetime(news_api_df['publishedAt'], infer_datetime_format=True)\n",
      "<ipython-input-416-cdfc1be087f2>:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  news_api_df['clean_title'] = news_api_clean_title\n",
      "<ipython-input-416-cdfc1be087f2>:38: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  news_api_df['clean_description'] = news_api_clean_desc\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    query = 'cryptocurrency'\n",
    "    headers = {\n",
    "        'accept': '*/*',\n",
    "        'accept-encoding': 'gzip, deflate, br',\n",
    "        'accept-language': 'en-US,en;q=0.9',\n",
    "        'referer': 'https://www.google.com',\n",
    "        'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/85.0.4183.83 Safari/537.36 Edg/85.0.564.44'\n",
    "    }\n",
    "    date = date.today().strftime(\"%Y%m%d\")\n",
    "    todays_date = date.today().strftime(\"%Y-%m-%d\")\n",
    "    yesterdays_date = (date.today() - timedelta(days=1)).strftime(\"%Y-%m-%d\")\n",
    "\n",
    "    article_cleaner = ArticleCleaner()\n",
    "    yahoo_article_streamer = YahooArticleStreamer()\n",
    "    \n",
    "    news_api_streamer = NewsAPIArticleStreamer()\n",
    "    news_api_cleaner = NewsAPIArticleCleaner()\n",
    "    \n",
    "    sentiment_analyzer = SentimentAnalyzer()\n",
    "\n",
    "    #news_api_articles = news_api_streamer.stream_articles(query, yesterdays_date, todays_date)\n",
    "    #yahoo_articles = yahoo_article_streamer.get_the_news(query)\n",
    "        \n",
    "    news_article_data = pd.json_normalize(news_api_articles['articles'])\n",
    "    news_api_df, outlets = article_cleaner.create_article(news_article_data)\n",
    "    news_api_df['publishedAt'] = pd.to_datetime(news_api_df['publishedAt'], infer_datetime_format=True)\n",
    "    \n",
    "    yahoo_clean_title = np.array([article_cleaner.clean_article(article) for article in yahoo_articles['title']])\n",
    "    yahoo_clean_desc = np.array([article_cleaner.clean_article(article) for article in yahoo_articles['description']])\n",
    "    \n",
    "    news_api_clean_title = np.array([article_cleaner.clean_article(article) for article in news_api_df['title']])\n",
    "    news_api_clean_desc = np.array([article_cleaner.clean_article(article) for article in news_api_df['description']])\n",
    "    \n",
    "    yahoo_articles['clean_title'] = yahoo_clean_title\n",
    "    yahoo_articles['clean_description'] = yahoo_clean_desc\n",
    "    \n",
    "    news_api_df['clean_title'] = news_api_clean_title\n",
    "    news_api_df['clean_description'] = news_api_clean_desc\n",
    "    \n",
    "    recent_yahoo_articles = article_cleaner.get_recent_articles(yahoo_articles)\n",
    "    \n",
    "    yahoo_scored_news = sentiment_analyzer.analyze_recent_headlines(recent_yahoo_articles)\n",
    "    news_api_scored_news = sentiment_analyzer.analyze_recent_headlines(news_api_df)\n",
    "    \n",
    "    high_yahoo_news = yahoo_scored_news[(yahoo_scored_news['compound'] > .5) | (yahoo_scored_news['compound'] < -0.5)]\n",
    "    high_news_api_news = news_api_scored_news[(news_api_scored_news['compound'] > .5) | (news_api_scored_news['compound'] < -0.5)]\n",
    "    \n",
    "    final_yahoo_news = high_yahoo_news[['publishedAt','clean_title','compound']]\n",
    "    final_news_api = high_news_api_news[['publishedAt','clean_title','compound']]\n",
    "    \n",
    "    final_news = final_yahoo_news.append(final_news_api)\n",
    "    final_news = final_news.reset_index(drop=True)\n",
    "    \n",
    "    final_news['date'] = pd.to_datetime(final_news['publishedAt'], format='%Y-%m-%d')\n",
    "    final_news['date'] = final_news['date'].dt.strftime('%Y-%m-%d')\n",
    "    \n",
    "    final_news.to_csv(f'.\\{date}sentiment.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>publishedAt</th>\n",
       "      <th>clean_title</th>\n",
       "      <th>compound</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-01-25 13:59:05</td>\n",
       "      <td>Big Investors Stacked Up Ether as Price Rose t...</td>\n",
       "      <td>0.9818</td>\n",
       "      <td>2021-01-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-01-26 03:59:05</td>\n",
       "      <td>Harvard and Yale Endowments Among Those Report...</td>\n",
       "      <td>0.9325</td>\n",
       "      <td>2021-01-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-01-26 10:59:05</td>\n",
       "      <td>Bitcoin BTC Continues to Struggle While Ethere...</td>\n",
       "      <td>0.9682</td>\n",
       "      <td>2021-01-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-01-26 02:59:05</td>\n",
       "      <td>Bearish Divergence Hints At First Major Chainl...</td>\n",
       "      <td>-0.9970</td>\n",
       "      <td>2021-01-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-01-25 16:59:05</td>\n",
       "      <td>Bitcoin price rises as second biggest cryptocu...</td>\n",
       "      <td>0.9682</td>\n",
       "      <td>2021-01-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2021-01-26 12:35:05</td>\n",
       "      <td>ETH breaks out vs Bitcoin What s next for Ethe...</td>\n",
       "      <td>0.9818</td>\n",
       "      <td>2021-01-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2021-01-25 13:59:05</td>\n",
       "      <td>Here s Why Ethereum Could Beat Bitcoin As Best...</td>\n",
       "      <td>0.7717</td>\n",
       "      <td>2021-01-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2021-01-25 15:59:05</td>\n",
       "      <td>Grayscale donates 1M to Coin Center pledges up...</td>\n",
       "      <td>0.7906</td>\n",
       "      <td>2021-01-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2021-01-25 20:59:05</td>\n",
       "      <td>All risk no gain The vague definition of stabl...</td>\n",
       "      <td>0.9705</td>\n",
       "      <td>2021-01-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2021-01-25 15:59:05</td>\n",
       "      <td>First Mover Bitcoin Flushes Weak Hands as Ethe...</td>\n",
       "      <td>0.9590</td>\n",
       "      <td>2021-01-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2021-01-25 13:59:05</td>\n",
       "      <td>Big Investors Stacked up Ether as Price Rose t...</td>\n",
       "      <td>0.9818</td>\n",
       "      <td>2021-01-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2021-01-25 13:59:05</td>\n",
       "      <td>Ethereum explodes 21 in just one day to secure...</td>\n",
       "      <td>0.9732</td>\n",
       "      <td>2021-01-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2021-01-25 18:59:05</td>\n",
       "      <td>I ve been convinced to buy Bitcoin the odds ar...</td>\n",
       "      <td>0.6808</td>\n",
       "      <td>2021-01-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2021-01-25 17:59:05</td>\n",
       "      <td>Crypto Markets Show More Signs of Excess Amid ...</td>\n",
       "      <td>0.9818</td>\n",
       "      <td>2021-01-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2021-01-25 22:59:05</td>\n",
       "      <td>Substack Newsletters Are Being Used to Spread ...</td>\n",
       "      <td>-0.5859</td>\n",
       "      <td>2021-01-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2021-01-25 21:59:05</td>\n",
       "      <td>Grayscale Gifts 1 Million To Coin Center Will ...</td>\n",
       "      <td>0.7906</td>\n",
       "      <td>2021-01-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2021-01-25 23:59:05</td>\n",
       "      <td>Harvard Yale Brown Endowments Have Been Buying...</td>\n",
       "      <td>0.9325</td>\n",
       "      <td>2021-01-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2021-01-26 08:59:05</td>\n",
       "      <td>Signal is drama free for now but it should pre...</td>\n",
       "      <td>-0.9944</td>\n",
       "      <td>2021-01-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2021-01-26 08:59:05</td>\n",
       "      <td>FOREX Dollar gains as stimulus nerves nudge in...</td>\n",
       "      <td>0.9840</td>\n",
       "      <td>2021-01-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2021-01-25 20:59:05</td>\n",
       "      <td>Marathon Patent Is Not a Wise Play Even for Cr...</td>\n",
       "      <td>0.8862</td>\n",
       "      <td>2021-01-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2021-01-25 14:59:05</td>\n",
       "      <td>Two Arrested for Orchestrating Escape of Wirec...</td>\n",
       "      <td>-0.8126</td>\n",
       "      <td>2021-01-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2021-01-25 22:59:05</td>\n",
       "      <td>45B DeFi market cap and soaring TVL suggest th...</td>\n",
       "      <td>0.9986</td>\n",
       "      <td>2021-01-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2021-01-25 19:59:05</td>\n",
       "      <td>The Soul Killing Wallet Emptying Struggle to B...</td>\n",
       "      <td>-0.8074</td>\n",
       "      <td>2021-01-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2021-01-25 16:59:05</td>\n",
       "      <td>The Most Actively Traded Securities On OTC Mar...</td>\n",
       "      <td>0.6195</td>\n",
       "      <td>2021-01-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2021-01-26 12:35:05</td>\n",
       "      <td>Opening Bell Stimulus Bets Expected Earnings B...</td>\n",
       "      <td>0.8979</td>\n",
       "      <td>2021-01-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2021-01-25 14:59:05</td>\n",
       "      <td>Two Arrested for Orchestrating Escape of Wirec...</td>\n",
       "      <td>-0.8126</td>\n",
       "      <td>2021-01-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2021-01-26 06:59:05</td>\n",
       "      <td>FOREX Dollar gains as stimulus nerves nudge in...</td>\n",
       "      <td>0.9840</td>\n",
       "      <td>2021-01-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2021-01-26 06:59:05</td>\n",
       "      <td>FOREX Dollar gains as stimulus nerves nudge in...</td>\n",
       "      <td>0.9840</td>\n",
       "      <td>2021-01-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2021-01-25 22:59:05</td>\n",
       "      <td>Substack Newsletters Are Being Used to Spread ...</td>\n",
       "      <td>-0.5859</td>\n",
       "      <td>2021-01-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2021-01-25 23:59:05</td>\n",
       "      <td>Harvard Yale Brown Endowments Have Been Buying...</td>\n",
       "      <td>0.9325</td>\n",
       "      <td>2021-01-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2021-01-26 12:12:05</td>\n",
       "      <td>These 5 charts show why Bitcoin price failed t...</td>\n",
       "      <td>-0.5106</td>\n",
       "      <td>2021-01-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>2021-01-26 07:07:40</td>\n",
       "      <td>Signal is drama free for now but it should pre...</td>\n",
       "      <td>-0.9944</td>\n",
       "      <td>2021-01-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>2021-01-25 11:29:14</td>\n",
       "      <td>Big Investors Stacked up Ether as Price Rose t...</td>\n",
       "      <td>0.9818</td>\n",
       "      <td>2021-01-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>2021-01-25 00:39:19</td>\n",
       "      <td>Ethereum s Ether Cryptocurrency Sets New All T...</td>\n",
       "      <td>0.9682</td>\n",
       "      <td>2021-01-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>2021-01-25 20:34:46</td>\n",
       "      <td>Substack Newsletters Are Being Used to Spread ...</td>\n",
       "      <td>-0.5859</td>\n",
       "      <td>2021-01-25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            publishedAt                                        clean_title  \\\n",
       "0   2021-01-25 13:59:05  Big Investors Stacked Up Ether as Price Rose t...   \n",
       "1   2021-01-26 03:59:05  Harvard and Yale Endowments Among Those Report...   \n",
       "2   2021-01-26 10:59:05  Bitcoin BTC Continues to Struggle While Ethere...   \n",
       "3   2021-01-26 02:59:05  Bearish Divergence Hints At First Major Chainl...   \n",
       "4   2021-01-25 16:59:05  Bitcoin price rises as second biggest cryptocu...   \n",
       "5   2021-01-26 12:35:05  ETH breaks out vs Bitcoin What s next for Ethe...   \n",
       "6   2021-01-25 13:59:05  Here s Why Ethereum Could Beat Bitcoin As Best...   \n",
       "7   2021-01-25 15:59:05  Grayscale donates 1M to Coin Center pledges up...   \n",
       "8   2021-01-25 20:59:05  All risk no gain The vague definition of stabl...   \n",
       "9   2021-01-25 15:59:05  First Mover Bitcoin Flushes Weak Hands as Ethe...   \n",
       "10  2021-01-25 13:59:05  Big Investors Stacked up Ether as Price Rose t...   \n",
       "11  2021-01-25 13:59:05  Ethereum explodes 21 in just one day to secure...   \n",
       "12  2021-01-25 18:59:05  I ve been convinced to buy Bitcoin the odds ar...   \n",
       "13  2021-01-25 17:59:05  Crypto Markets Show More Signs of Excess Amid ...   \n",
       "14  2021-01-25 22:59:05  Substack Newsletters Are Being Used to Spread ...   \n",
       "15  2021-01-25 21:59:05  Grayscale Gifts 1 Million To Coin Center Will ...   \n",
       "16  2021-01-25 23:59:05  Harvard Yale Brown Endowments Have Been Buying...   \n",
       "17  2021-01-26 08:59:05  Signal is drama free for now but it should pre...   \n",
       "18  2021-01-26 08:59:05  FOREX Dollar gains as stimulus nerves nudge in...   \n",
       "19  2021-01-25 20:59:05  Marathon Patent Is Not a Wise Play Even for Cr...   \n",
       "20  2021-01-25 14:59:05  Two Arrested for Orchestrating Escape of Wirec...   \n",
       "21  2021-01-25 22:59:05  45B DeFi market cap and soaring TVL suggest th...   \n",
       "22  2021-01-25 19:59:05  The Soul Killing Wallet Emptying Struggle to B...   \n",
       "23  2021-01-25 16:59:05  The Most Actively Traded Securities On OTC Mar...   \n",
       "24  2021-01-26 12:35:05  Opening Bell Stimulus Bets Expected Earnings B...   \n",
       "25  2021-01-25 14:59:05  Two Arrested for Orchestrating Escape of Wirec...   \n",
       "26  2021-01-26 06:59:05  FOREX Dollar gains as stimulus nerves nudge in...   \n",
       "27  2021-01-26 06:59:05  FOREX Dollar gains as stimulus nerves nudge in...   \n",
       "28  2021-01-25 22:59:05  Substack Newsletters Are Being Used to Spread ...   \n",
       "29  2021-01-25 23:59:05  Harvard Yale Brown Endowments Have Been Buying...   \n",
       "30  2021-01-26 12:12:05  These 5 charts show why Bitcoin price failed t...   \n",
       "31  2021-01-26 07:07:40  Signal is drama free for now but it should pre...   \n",
       "32  2021-01-25 11:29:14  Big Investors Stacked up Ether as Price Rose t...   \n",
       "33  2021-01-25 00:39:19  Ethereum s Ether Cryptocurrency Sets New All T...   \n",
       "34  2021-01-25 20:34:46  Substack Newsletters Are Being Used to Spread ...   \n",
       "\n",
       "    compound        date  \n",
       "0     0.9818  2021-01-25  \n",
       "1     0.9325  2021-01-26  \n",
       "2     0.9682  2021-01-26  \n",
       "3    -0.9970  2021-01-26  \n",
       "4     0.9682  2021-01-25  \n",
       "5     0.9818  2021-01-26  \n",
       "6     0.7717  2021-01-25  \n",
       "7     0.7906  2021-01-25  \n",
       "8     0.9705  2021-01-25  \n",
       "9     0.9590  2021-01-25  \n",
       "10    0.9818  2021-01-25  \n",
       "11    0.9732  2021-01-25  \n",
       "12    0.6808  2021-01-25  \n",
       "13    0.9818  2021-01-25  \n",
       "14   -0.5859  2021-01-25  \n",
       "15    0.7906  2021-01-25  \n",
       "16    0.9325  2021-01-25  \n",
       "17   -0.9944  2021-01-26  \n",
       "18    0.9840  2021-01-26  \n",
       "19    0.8862  2021-01-25  \n",
       "20   -0.8126  2021-01-25  \n",
       "21    0.9986  2021-01-25  \n",
       "22   -0.8074  2021-01-25  \n",
       "23    0.6195  2021-01-25  \n",
       "24    0.8979  2021-01-26  \n",
       "25   -0.8126  2021-01-25  \n",
       "26    0.9840  2021-01-26  \n",
       "27    0.9840  2021-01-26  \n",
       "28   -0.5859  2021-01-25  \n",
       "29    0.9325  2021-01-25  \n",
       "30   -0.5106  2021-01-26  \n",
       "31   -0.9944  2021-01-26  \n",
       "32    0.9818  2021-01-25  \n",
       "33    0.9682  2021-01-25  \n",
       "34   -0.5859  2021-01-25  "
      ]
     },
     "execution_count": 419,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15.214999999999998"
      ]
     },
     "execution_count": 385,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_news['compound'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_dates = final_news['Date'].unique()\n",
    "grouped_dates = final_news.groupby(['Date'])\n",
    "keys_dates = list(grouped_dates.groups.keys())\n",
    "\n",
    "max_cs = []\n",
    "min_cs = []\n",
    "\n",
    "for key in grouped_dates.groups.keys():\n",
    "    data = grouped_dates.get_group(key)\n",
    "    if data[\"compound_vader_score\"].max() > 0:\n",
    "        max_cs.append(data[\"compound_vader_score\"].max())\n",
    "    elif data[\"compound_vader_score\"].max() < 0:\n",
    "        max_cs.append(0)\n",
    "    \n",
    "    if data[\"compound_vader_score\"].min() < 0:\n",
    "        min_cs.append(data[\"compound_vader_score\"].min())\n",
    "    elif data[\"compound_vader_score\"].min() > 0:\n",
    "        min_cs.append(0)\n",
    "    \n",
    "extreme_scores_dict = {'Date':keys_dates,'max_scores':max_cs,'min_scores':min_cs}\n",
    "extreme_scores_df = pd.DataFrame(extreme_scores_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'extreme_scores_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-371-5e1a60df00cb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mvader_Buy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mvader_Sell\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mextreme_scores_df\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mextreme_scores_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'final_scores'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0.20\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Trade Call for {row} is Buy.\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mextreme_scores_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Date'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'extreme_scores_df' is not defined"
     ]
    }
   ],
   "source": [
    "# VADER trade calls - with threshold\n",
    "vader_Buy=[]\n",
    "vader_Sell=[]\n",
    "for i in range(len(extreme_scores_df)):\n",
    "    if extreme_scores_df['final_scores'].values[i] > 0.20:\n",
    "        print(\"Trade Call for {row} is Buy.\".format(row=extreme_scores_df['Date'].iloc[i].date()))\n",
    "        vader_Buy.append(extreme_scores_df['Date'].iloc[i].date())\n",
    "    elif extreme_scores_df['final_scores'].values[i] < -0.20:\n",
    "        print(\"Trade Call for {row} is Sell.\".format(row=extreme_scores_df['Date'].iloc[i].date()))\n",
    "        vader_Sell.append(extreme_scores_df['Date'].iloc[i].date())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
