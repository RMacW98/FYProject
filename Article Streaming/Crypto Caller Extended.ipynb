{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import csv\n",
    "from time import sleep\n",
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests, bs4\n",
    "from bs4 import BeautifulSoup\n",
    "import datetime\n",
    "from datetime import datetime, timedelta, date\n",
    "\n",
    "import pandas_datareader as pdr\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from yahoofinancials import YahooFinancials\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # # NEWS API STREAMER # # # #\n",
    "class ArticleStreamer():\n",
    "    \"\"\"\n",
    "    Class for streaming and processing articles daily\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def get_article(self, card):\n",
    "        \"\"\"Extract article information from the raw html\"\"\"\n",
    "        headline = card.find('h4', 's-title').text\n",
    "        source = card.find(\"span\", 's-source').text\n",
    "        posted = card.find('span', 's-time').text.replace('Â·', '').strip()\n",
    "        description = card.find('p', 's-desc').text.strip()\n",
    "        raw_link = card.find('a').get('href')\n",
    "        unquoted_link = requests.utils.unquote(raw_link)\n",
    "        pattern = re.compile(r'RU=(.+)\\/RK')\n",
    "        clean_link = re.search(pattern, unquoted_link).group(1)\n",
    "\n",
    "        article = (headline, source, posted, description, clean_link)\n",
    "        return article\n",
    "\n",
    "    def get_the_news(self, query):\n",
    "        \"\"\"Run the main program\"\"\"\n",
    "        article_headers = ['title', 'outlet', 'uploaded', 'description', 'url']\n",
    "        \n",
    "        template = 'https://news.search.yahoo.com/search?p={}'\n",
    "        url = template.format(query)\n",
    "        articles = []\n",
    "        links = set()\n",
    "\n",
    "        while True:\n",
    "            response = requests.get(url, headers=headers)\n",
    "            soup = BeautifulSoup(response.text, 'html.parser')\n",
    "            cards = soup.find_all('div', 'NewsArticle')\n",
    "\n",
    "            # extract articles from page\n",
    "            for card in cards:\n",
    "                article = self.get_article(card)\n",
    "                link = article[-1]\n",
    "                if not link in links:\n",
    "                    links.add(link)\n",
    "                    articles.append(article)\n",
    "\n",
    "                    # find the next page\n",
    "            try:\n",
    "                url = soup.find('a', 'next').get('href')\n",
    "                sleep(1)\n",
    "            except AttributeError:\n",
    "                break\n",
    "        \n",
    "        all_articles = pd.DataFrame(articles, columns = article_headers)\n",
    "\n",
    "        #for article in all_articles:\n",
    "        #    if article.uploaded\n",
    "        \n",
    "        return all_articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ArticleCleaner():\n",
    "    \"\"\"\n",
    "    Functionality for importing and cleaning news articles\n",
    "    \"\"\"\n",
    "\n",
    "    def import_json(self, fetched_json_file):\n",
    "        # Import json and normalize data\n",
    "        df = pd.read_json(fetched_json_file)\n",
    "        norm_articles = pd.json_normalize(df['articles'])\n",
    "\n",
    "        return norm_articles\n",
    "\n",
    "    def clean_article(self, article):\n",
    "        \n",
    "        return ' '.join(re.sub(\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\", \" \", article).split())\n",
    "\n",
    "    def create_article(self, articles):\n",
    "        article = articles[['author', 'title', 'description', 'url', 'source.name', 'publishedAt']]\n",
    "        outlet = articles[['source.id', 'source.name']]\n",
    "\n",
    "        return article, outlet\n",
    "    \n",
    "    def get_recent_articles(self, all_articles):\n",
    "        recent_articles = pd.DataFrame()\n",
    "\n",
    "        for index, row in all_articles.iterrows():\n",
    "            if 'hour' in row.uploaded:\n",
    "                recent_articles = recent_articles.append(row)\n",
    "\n",
    "            if 'minute' in row.uploaded:\n",
    "                recent_articles = recent_articles.append(row)\n",
    "\n",
    "            if 'second' in row.uploaded:\n",
    "                recent_articles = recent_articles.append(row)\n",
    "\n",
    "        time = []\n",
    "        hours = recent_articles['uploaded'].str.split(' ')\n",
    "        df = pd.DataFrame(hours.values.tolist(), index=hours.index)\n",
    "        hours_ago = df[0]\n",
    "\n",
    "        for index, hours in hours_ago.items():\n",
    "            if hours < 24:\n",
    "                d = datetime.today() - timedelta(hours=int(hours), minutes=0)\n",
    "                time.append(d.strftime(\"%Y-%m-%d %H:%M\"))\n",
    "            else:\n",
    "                d = datetime.today() - timedelta(hours=0, minutes=int(hours))\n",
    "                time.append(d.strftime(\"%Y-%m-%d %H:%M\"))\n",
    "        \n",
    "        recent_articles['publishedAt'] = time\n",
    "        recent_articles = recent_articles.drop(['uploaded'])\n",
    "\n",
    "        return recent_articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentimentAnalyzer():\n",
    "    \"\"\"\n",
    "    Functionality for analyzing headlines sentiment\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.data = pd.read_csv('./datasets/headlines_labelled.txt',\n",
    "                        sep='\\t', header= None)\n",
    "        self.scores_df = pd.DataFrame()\n",
    "        \n",
    "        # New words and values\n",
    "        self.new_words = {\n",
    "            'crushes': 10,\n",
    "            'beats': 5,\n",
    "            'misses': -5,\n",
    "            'trouble': -10,\n",
    "            'falls': -100,\n",
    "            'slides': -50,\n",
    "            'slide': -50,\n",
    "            'record high': 15,\n",
    "            'low': -15,\n",
    "            'one week low': -30,\n",
    "            'worth more': 5,\n",
    "            'digital gold': 5,\n",
    "            'high': 15,\n",
    "            'cryptocurrency fund': 10,\n",
    "            'up': 5,\n",
    "            'soars': 70,\n",
    "            'rebound': 20,\n",
    "            'pullback': -40,\n",
    "            'slumps': -60,\n",
    "            'jumps': 50,\n",
    "            'record low': -100,\n",
    "            'soaring': 70,\n",
    "            'bearish': -50,\n",
    "            'bullish': 50,\n",
    "            'bulls': 10,\n",
    "            'bears' : -10,\n",
    "            'hodl': 10,\n",
    "            'pulls back': -40,\n",
    "            'selloff': -70,\n",
    "            'retrace': -70,\n",
    "            'drop': -50,\n",
    "            'buying': 10,\n",
    "            'selling': -10,\n",
    "            'rally': 15,\n",
    "            'bounces': 20,\n",
    "            'testing support': -5,\n",
    "            'climb': 5,\n",
    "            'rise': 20,\n",
    "            'crashes': -100,\n",
    "            'crash': -100,\n",
    "            'downward': -30,\n",
    "            'plunges': -100,\n",
    "            'plunge' : -80,\n",
    "            'cardano': 0,\n",
    "            'descends': -30,\n",
    "            'descend': -30,\n",
    "            'gain' : 20,\n",
    "            'gains' : 20,\n",
    "            'worst' : -25,\n",
    "            'loss' : -15,\n",
    "            'without risk': 10,\n",
    "            'tumbles': -50,\n",
    "            'jeopardy': -50\n",
    "        }\n",
    "        \n",
    "        \n",
    "    def reading_dataset(self):\n",
    "        columnName = ['Headlines','Sentiment']\n",
    "        self.data.columns = columnName\n",
    "        self.data.head()\n",
    "        \n",
    "        return self.data\n",
    "    \n",
    "    \n",
    "    def analyze_test_headlines(self):        \n",
    "        # Instantiate the sentiment intensity analyzer with the existing lexicon\n",
    "        vader = SentimentIntensityAnalyzer()\n",
    "        \n",
    "        # Update the lexicon\n",
    "        vader.lexicon.update(self.new_words)\n",
    "        \n",
    "        data = self.reading_dataset()\n",
    "        \n",
    "        # Iterate through the headlines and get the polarity scores\n",
    "        scores = data['Headlines'].apply(vader.polarity_scores)\n",
    "        \n",
    "        # Convert the list of dicts into a DataFrame\n",
    "        scores_df = pd.DataFrame.from_records(scores)\n",
    "\n",
    "        # Join the DataFrames\n",
    "        scored_news = data.join(scores_df)\n",
    "        \n",
    "        scored_news['assigned_label'] = scored_news['Sentiment'].apply(lambda Sentiment: 'pos' if Sentiment>0 else 'neg')\n",
    "        scored_news['predicted_label'] = scored_news['compound'].apply(lambda compound: 'pos' if compound>=0 else 'neg')\n",
    "        \n",
    "        return scored_news\n",
    "    \n",
    "    def analyze_recent_headlines(self, data):        \n",
    "        # Instantiate the sentiment intensity analyzer with the existing lexicon\n",
    "        vader = SentimentIntensityAnalyzer()\n",
    "        \n",
    "        # Update the lexicon\n",
    "        vader.lexicon.update(self.new_words)\n",
    "        \n",
    "        # Iterate through the headlines and get the polarity scores\n",
    "        #scores = data['clean_title'].apply(vader.polarity_scores)\n",
    "        \n",
    "        self.scores_df['neg'] = [vader.polarity_scores(x)['neg'] for x in data['clean_title']]\n",
    "        self.scores_df['neu'] = [vader.polarity_scores(x)['neu'] for x in data['clean_title']]\n",
    "        self.scores_df['pos'] = [vader.polarity_scores(x)['pos'] for x in data['clean_title']]\n",
    "        self.scores_df['compound'] = [vader.polarity_scores(x)['compound'] for x in data['clean_title']]\n",
    "        \n",
    "        # Convert the list of dicts into a DataFrame\n",
    "        #scores_df = pd.DataFrame.from_records(scores)\n",
    "\n",
    "        # Join the DataFrames\n",
    "        data = data.reset_index()\n",
    "        scored_news = data.merge(self.scores_df,left_index=True, right_index=True, how='inner')\n",
    "        \n",
    "        scored_news['predicted_label'] = scored_news['compound'].apply(lambda compound: 'pos' if compound > 0 else ('neu' if compound == 0 else 'neg'))\n",
    "        \n",
    "        return scored_news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PriceStreamer():\n",
    "    \"\"\"\n",
    "    Functionality for constantly streaming BTC price\n",
    "    \"\"\"\n",
    "    def parse_price():\n",
    "        res = requests.get('https://finance.yahoo.com/quote/BTC-USD?p=BTC-USD&.tsrc=fin-srch')\n",
    "        soup = bs4.BeautifulSoup(res.text, 'lxml')\n",
    "\n",
    "        price = soup.find_all('span', class_='Trsdu(0.3s) Fw(b) Fz(36px) Mb(-4px) D(ib)')[0].text\n",
    "        price_change = soup.find_all('span', class_='Trsdu(0.3s) Fw(500) Pstart(10px) Fz(24px) C($positiveColor)')[0].text\n",
    "\n",
    "        return price, price_change\n",
    "    \n",
    "    def get_hist_data():\n",
    "        cryptocurrencies = ['BTC-USD', 'ETH-USD', 'ADA-USD']\n",
    "        yahoo_financials_cryptocurrencies = YahooFinancials(cryptocurrencies)\n",
    "\n",
    "        d6 = (datetime.date.today() - datetime.timedelta(days=6)).strftime(\"%Y-%m-%d\")\n",
    "        d13 = (datetime.date.today() - datetime.timedelta(days=13)).strftime(\"%Y-%m-%d\")\n",
    "\n",
    "        daily_crypto_prices = yahoo_financials_cryptocurrencies.get_historical_price_data(d12, d6, 'daily')\n",
    "        data = pd.DataFrame.from_records(daily_crypto_prices)\n",
    "        price_df = pd.json_normalize(data['BTC-USD']['prices'])\n",
    "        \n",
    "        return price_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    query = 'cryptocurrency'\n",
    "    headers = {\n",
    "        'accept': '*/*',\n",
    "        'accept-encoding': 'gzip, deflate, br',\n",
    "        'accept-language': 'en-US,en;q=0.9',\n",
    "        'referer': 'https://www.google.com',\n",
    "        'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/85.0.4183.83 Safari/537.36 Edg/85.0.564.44'\n",
    "    }\n",
    "    todays_date = date.today().strftime(\"%d%m%Y\")\n",
    "\n",
    "    article_cleaner = ArticleCleaner()\n",
    "    article_streamer = ArticleStreamer()\n",
    "    sentiment_analyzer = SentimentAnalyzer()\n",
    "\n",
    "    #all_articles = article_streamer.get_the_news(query)\n",
    "\n",
    "    clean_title = np.array([article_cleaner.clean_article(article) for article in all_articles['title']])\n",
    "    clean_desc = np.array([article_cleaner.clean_article(article) for article in all_articles['description']])\n",
    "\n",
    "    all_articles['clean_title'] = clean_title\n",
    "    all_articles['clean_description'] = clean_desc\n",
    "    \n",
    "    recent_articles = article_cleaner.get_recent_articles(all_articles)\n",
    "    \n",
    "    scored_news = sentiment_analyzer.analyze_recent_headlines(recent_articles)\n",
    "    \n",
    "    high_news = scored_news[(scored_news['compound'] > .5) | (scored_news['compound'] < -0.5)]\n",
    "\n",
    "    high_news.to_csv(f'.\\{todays_date}sentiment.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "from yahoofinancials import YahooFinancials\n",
    "\n",
    "cryptocurrencies = ['BTC-USD', 'ETH-USD', 'ADA-USD']\n",
    "yahoo_financials_cryptocurrencies = YahooFinancials(cryptocurrencies)\n",
    "\n",
    "d6 = (datetime.date.today() - datetime.timedelta(days=6)).strftime(\"%Y-%m-%d\")\n",
    "d12 = (datetime.date.today() - datetime.timedelta(days=12)).strftime(\"%Y-%m-%d\")\n",
    "\n",
    "daily_crypto_prices = yahoo_financials_cryptocurrencies.get_historical_price_data(d12, d6, 'daily')\n",
    "data = pd.DataFrame.from_records(daily_crypto_prices)\n",
    "price_df = pd.json_normalize(data['BTC-USD']['prices'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_description</th>\n",
       "      <th>clean_title</th>\n",
       "      <th>description</th>\n",
       "      <th>outlet</th>\n",
       "      <th>title</th>\n",
       "      <th>uploaded</th>\n",
       "      <th>url</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Strong hands look to have been backing the rec...</td>\n",
       "      <td>Big Investors Stacked Up Ether as Price Rose t...</td>\n",
       "      <td>Strong hands look to have been backing the rec...</td>\n",
       "      <td>CoinDesk via Yahoo Finance</td>\n",
       "      <td>Big Investors Stacked Up Ether as Price Rose t...</td>\n",
       "      <td>22 hours ago</td>\n",
       "      <td>https://finance.yahoo.com/news/big-investors-s...</td>\n",
       "      <td>2021-01-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Investment flows into cryptocurrency funds and...</td>\n",
       "      <td>Bitcoin crypto inflows hit record last week Co...</td>\n",
       "      <td>Investment flows into cryptocurrency funds and...</td>\n",
       "      <td>Reuters via Yahoo Finance</td>\n",
       "      <td>Bitcoin, crypto inflows hit record last week -...</td>\n",
       "      <td>7 hours ago</td>\n",
       "      <td>https://finance.yahoo.com/news/bitcoin-crypto-...</td>\n",
       "      <td>2021-01-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>The vertiginous rise that the price of Bitcoin...</td>\n",
       "      <td>Bitcoin May Never Go Above 40 000 Again JP Mor...</td>\n",
       "      <td>The vertiginous rise that the price of Bitcoin...</td>\n",
       "      <td>Entrepreneur via Yahoo Finance</td>\n",
       "      <td>Bitcoin May Never Go Above $ 40,000 Again, JP ...</td>\n",
       "      <td>15 hours ago</td>\n",
       "      <td>https://finance.yahoo.com/news/bitcoin-may-nev...</td>\n",
       "      <td>2021-01-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>The pace of flows into the 20 billion Grayscal...</td>\n",
       "      <td>Bitcoin Return to 40 000 in Doubt as Flows to ...</td>\n",
       "      <td>The pace of flows into the $20 billion Graysca...</td>\n",
       "      <td>Bloomberg via Yahoo Finance</td>\n",
       "      <td>Bitcoin Return to $40,000 in Doubt as Flows to...</td>\n",
       "      <td>23 hours ago</td>\n",
       "      <td>https://finance.yahoo.com/news/bitcoin-return-...</td>\n",
       "      <td>2021-01-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Bitcoin s price could exceed 50 000 over the l...</td>\n",
       "      <td>Bitcoin Seen Topping 50 000 Long Term as it Vi...</td>\n",
       "      <td>Bitcoinâs price could exceed $50,000 over the ...</td>\n",
       "      <td>Bloomberg</td>\n",
       "      <td>Bitcoin Seen Topping $50,000 Long Term as it V...</td>\n",
       "      <td>5 hours ago</td>\n",
       "      <td>https://www.bloomberg.com/news/articles/2021-0...</td>\n",
       "      <td>2021-01-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>549</th>\n",
       "      <td>Futures The Dow futures are up by 0 13 and the...</td>\n",
       "      <td>Global Markets Start Week On Positive Note Eth...</td>\n",
       "      <td>Futures: The Dow futures are up by 0.13%, and ...</td>\n",
       "      <td>Benzinga via Yahoo Finance</td>\n",
       "      <td>Global Markets Start Week On Positive Note, Et...</td>\n",
       "      <td>24 hours ago</td>\n",
       "      <td>https://finance.yahoo.com/news/global-markets-...</td>\n",
       "      <td>2021-01-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>550</th>\n",
       "      <td>The U K s former cybersecurity chief has said ...</td>\n",
       "      <td>Former UK Cybersecurity Chief Says Laws Needed...</td>\n",
       "      <td>The U.K.âs former cybersecurity chief has said...</td>\n",
       "      <td>Coindesk</td>\n",
       "      <td>Former UK Cybersecurity Chief Says Laws Needed...</td>\n",
       "      <td>24 hours ago</td>\n",
       "      <td>https://www.coindesk.com/former-uk-cybersecuri...</td>\n",
       "      <td>2021-01-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>580</th>\n",
       "      <td>In financial markets filled to the brim with f...</td>\n",
       "      <td>Crypto Markets Show More Signs of Excess Amid ...</td>\n",
       "      <td>In financial markets filled to the brim with f...</td>\n",
       "      <td>Bloomberg</td>\n",
       "      <td>Crypto Markets Show More Signs of Excess Amid ...</td>\n",
       "      <td>18 hours ago</td>\n",
       "      <td>https://www.bloomberg.com/news/articles/2021-0...</td>\n",
       "      <td>2021-01-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>583</th>\n",
       "      <td>We ll maintain our own presence everywhere we ...</td>\n",
       "      <td>Online merchants linked to QAnon down but not ...</td>\n",
       "      <td>\"We'll maintain our own presence everywhere we...</td>\n",
       "      <td>Reuters via AOL</td>\n",
       "      <td>Online merchants linked to QAnon down, but not...</td>\n",
       "      <td>20 hours ago</td>\n",
       "      <td>https://www.aol.com/online-merchants-linked-qa...</td>\n",
       "      <td>2021-01-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>588</th>\n",
       "      <td>Since last year entrepreneur Dustin Krieger ha...</td>\n",
       "      <td>Online merchants linked to QAnon down but not ...</td>\n",
       "      <td>Since last year, entrepreneur Dustin Krieger h...</td>\n",
       "      <td>Reuters via Yahoo News</td>\n",
       "      <td>Online merchants linked to QAnon down, but not...</td>\n",
       "      <td>21 hours ago</td>\n",
       "      <td>https://news.yahoo.com/online-merchants-linked...</td>\n",
       "      <td>2021-01-26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>92 rows Ã 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     clean_description  \\\n",
       "0    Strong hands look to have been backing the rec...   \n",
       "1    Investment flows into cryptocurrency funds and...   \n",
       "7    The vertiginous rise that the price of Bitcoin...   \n",
       "9    The pace of flows into the 20 billion Grayscal...   \n",
       "10   Bitcoin s price could exceed 50 000 over the l...   \n",
       "..                                                 ...   \n",
       "549  Futures The Dow futures are up by 0 13 and the...   \n",
       "550  The U K s former cybersecurity chief has said ...   \n",
       "580  In financial markets filled to the brim with f...   \n",
       "583  We ll maintain our own presence everywhere we ...   \n",
       "588  Since last year entrepreneur Dustin Krieger ha...   \n",
       "\n",
       "                                           clean_title  \\\n",
       "0    Big Investors Stacked Up Ether as Price Rose t...   \n",
       "1    Bitcoin crypto inflows hit record last week Co...   \n",
       "7    Bitcoin May Never Go Above 40 000 Again JP Mor...   \n",
       "9    Bitcoin Return to 40 000 in Doubt as Flows to ...   \n",
       "10   Bitcoin Seen Topping 50 000 Long Term as it Vi...   \n",
       "..                                                 ...   \n",
       "549  Global Markets Start Week On Positive Note Eth...   \n",
       "550  Former UK Cybersecurity Chief Says Laws Needed...   \n",
       "580  Crypto Markets Show More Signs of Excess Amid ...   \n",
       "583  Online merchants linked to QAnon down but not ...   \n",
       "588  Online merchants linked to QAnon down but not ...   \n",
       "\n",
       "                                           description  \\\n",
       "0    Strong hands look to have been backing the rec...   \n",
       "1    Investment flows into cryptocurrency funds and...   \n",
       "7    The vertiginous rise that the price of Bitcoin...   \n",
       "9    The pace of flows into the $20 billion Graysca...   \n",
       "10   Bitcoinâs price could exceed $50,000 over the ...   \n",
       "..                                                 ...   \n",
       "549  Futures: The Dow futures are up by 0.13%, and ...   \n",
       "550  The U.K.âs former cybersecurity chief has said...   \n",
       "580  In financial markets filled to the brim with f...   \n",
       "583  \"We'll maintain our own presence everywhere we...   \n",
       "588  Since last year, entrepreneur Dustin Krieger h...   \n",
       "\n",
       "                             outlet  \\\n",
       "0        CoinDesk via Yahoo Finance   \n",
       "1         Reuters via Yahoo Finance   \n",
       "7    Entrepreneur via Yahoo Finance   \n",
       "9       Bloomberg via Yahoo Finance   \n",
       "10                        Bloomberg   \n",
       "..                              ...   \n",
       "549      Benzinga via Yahoo Finance   \n",
       "550                        Coindesk   \n",
       "580                       Bloomberg   \n",
       "583                 Reuters via AOL   \n",
       "588          Reuters via Yahoo News   \n",
       "\n",
       "                                                 title      uploaded  \\\n",
       "0    Big Investors Stacked Up Ether as Price Rose t...  22 hours ago   \n",
       "1    Bitcoin, crypto inflows hit record last week -...   7 hours ago   \n",
       "7    Bitcoin May Never Go Above $ 40,000 Again, JP ...  15 hours ago   \n",
       "9    Bitcoin Return to $40,000 in Doubt as Flows to...  23 hours ago   \n",
       "10   Bitcoin Seen Topping $50,000 Long Term as it V...   5 hours ago   \n",
       "..                                                 ...           ...   \n",
       "549  Global Markets Start Week On Positive Note, Et...  24 hours ago   \n",
       "550  Former UK Cybersecurity Chief Says Laws Needed...  24 hours ago   \n",
       "580  Crypto Markets Show More Signs of Excess Amid ...  18 hours ago   \n",
       "583  Online merchants linked to QAnon down, but not...  20 hours ago   \n",
       "588  Online merchants linked to QAnon down, but not...  21 hours ago   \n",
       "\n",
       "                                                   url       date  \n",
       "0    https://finance.yahoo.com/news/big-investors-s... 2021-01-26  \n",
       "1    https://finance.yahoo.com/news/bitcoin-crypto-... 2021-01-26  \n",
       "7    https://finance.yahoo.com/news/bitcoin-may-nev... 2021-01-26  \n",
       "9    https://finance.yahoo.com/news/bitcoin-return-... 2021-01-26  \n",
       "10   https://www.bloomberg.com/news/articles/2021-0... 2021-01-26  \n",
       "..                                                 ...        ...  \n",
       "549  https://finance.yahoo.com/news/global-markets-... 2021-01-26  \n",
       "550  https://www.coindesk.com/former-uk-cybersecuri... 2021-01-26  \n",
       "580  https://www.bloomberg.com/news/articles/2021-0... 2021-01-26  \n",
       "583  https://www.aol.com/online-merchants-linked-qa... 2021-01-26  \n",
       "588  https://news.yahoo.com/online-merchants-linked... 2021-01-26  \n",
       "\n",
       "[92 rows x 8 columns]"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_news = high_news[['date','clean_title','compound']]\n",
    "recent_articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "recent_articles['publishedAt'] = time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22</td>\n",
       "      <td>hours</td>\n",
       "      <td>ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>hours</td>\n",
       "      <td>ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>15</td>\n",
       "      <td>hours</td>\n",
       "      <td>ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>23</td>\n",
       "      <td>hours</td>\n",
       "      <td>ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5</td>\n",
       "      <td>hours</td>\n",
       "      <td>ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>549</th>\n",
       "      <td>24</td>\n",
       "      <td>hours</td>\n",
       "      <td>ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>550</th>\n",
       "      <td>24</td>\n",
       "      <td>hours</td>\n",
       "      <td>ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>580</th>\n",
       "      <td>18</td>\n",
       "      <td>hours</td>\n",
       "      <td>ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>583</th>\n",
       "      <td>20</td>\n",
       "      <td>hours</td>\n",
       "      <td>ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>588</th>\n",
       "      <td>21</td>\n",
       "      <td>hours</td>\n",
       "      <td>ago</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>92 rows Ã 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0      1    2\n",
       "0    22  hours  ago\n",
       "1     7  hours  ago\n",
       "7    15  hours  ago\n",
       "9    23  hours  ago\n",
       "10    5  hours  ago\n",
       "..   ..    ...  ...\n",
       "549  24  hours  ago\n",
       "550  24  hours  ago\n",
       "580  18  hours  ago\n",
       "583  20  hours  ago\n",
       "588  21  hours  ago\n",
       "\n",
       "[92 rows x 3 columns]"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(hours.values.tolist(), index=hours.index)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
